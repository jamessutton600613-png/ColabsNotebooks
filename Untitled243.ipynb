{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsaITgmn1u4sLRFK3Jhp0m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamessutton600613-png/GC/blob/main/Untitled243.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB46uQXmUjiX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fafe50-57ae-42e9-e16a-d843f652ecfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gqr14_make_veracity_zip_v5.6_aligned.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile gqr14_make_veracity_zip_v5.6_aligned.py\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "GQRâ€“XIV â€” Single-Run Veracity ZIP (atomic provenance)\n",
        "v5.6-TYPO_FIX:\n",
        "- Fixes an 'AttributeError' typo from v5.5 (add_add_argument).\n",
        "- Retains all features from v5.5 (N-state, Z-axis standardization,\n",
        "  CPU fallback, tweakable resonance center, CIF bundling,\n",
        "  and plot y-axis tweak).\n",
        "\"\"\"\n",
        "import sys, os, json, time, math, hashlib, argparse, subprocess, io, zipfile, warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- MODIFIED: Robust GPU (CuPy) fallback ---\n",
        "try:\n",
        "    import cupy as cp\n",
        "    # Check if a CUDA device is *actually* available\n",
        "    if cp.cuda.runtime.getDeviceCount() > 0:\n",
        "        xp = cp\n",
        "        GPU_ON = True\n",
        "        print(\"[Info] CuPy imported and GPU device is AVAILABLE.\", file=sys.stderr)\n",
        "    else:\n",
        "        # CuPy is installed, but no device was found. Force fallback.\n",
        "        xp = np\n",
        "        GPU_ON = False\n",
        "        print(\"[Info] CuPy imported, but NO GPU device found. Falling back to CPU.\", file=sys.stderr)\n",
        "\n",
        "except ImportError:\n",
        "    # CuPy is not installed at all.\n",
        "    xp = np # Fallback to numpy\n",
        "    GPU_ON = False\n",
        "    print(\"[Info] CuPy not installed. Falling back to CPU.\", file=sys.stderr)\n",
        "except Exception as e:\n",
        "    # Other potential issues (e.g., CUDA driver mismatch)\n",
        "    xp = np\n",
        "    GPU_ON = False\n",
        "    print(f\"[Warning] GPU check failed unexpectedly ({e}). Falling back to CPU.\", file=sys.stderr)\n",
        "# --- END MODIFIED BLOCK ---\n",
        "\n",
        "\n",
        "# --- Ensure dependencies available (gemmi, pandas) ---\n",
        "try:\n",
        "    import gemmi\n",
        "    import pandas as pd\n",
        "except Exception:\n",
        "    print(\"[Info] Installing dependencies (gemmi, pandas)...\", file=sys.stderr)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"gemmi\", \"pandas\"], check=True)\n",
        "    import gemmi\n",
        "    import pandas as pd\n",
        "\n",
        "# This is the \"truth\" of the code. If this changes, the RUN_ID changes.\n",
        "CODE_VERSION = \"GQR14-TDSE-VERACITY-v5.6-TYPO_FIX\"\n",
        "\n",
        "# --- ðŸš€ TWEAKABLE PARAMETER ---\n",
        "# Set the default 's_total' index for the J metric resonance peak.\n",
        "# For your 9-file run (C,D,E,F,G,H,I,J,K), the 'I' state is at index 6.\n",
        "DEFAULT_RESONANCE_CENTER = 6.0\n",
        "# ---\n",
        "\n",
        "# ===================================================================\n",
        "# --- GEOMETRY (CIF) HELPERS ---\n",
        "# ===================================================================\n",
        "\n",
        "def get_first_two_atom_coords(path: str) -> np.ndarray:\n",
        "    try:\n",
        "        doc = gemmi.cif.read_file(path)\n",
        "        block = doc.sole_block()\n",
        "        xs = block.find_values('_atom_site.Cartn_x')\n",
        "        ys = block.find_values('_atom_site.Cartn_y')\n",
        "        zs = block.find_values('_atom_site.Cartn_z')\n",
        "        is_cartesian = True\n",
        "        if not xs or not ys or not zs:\n",
        "            xs = block.find_values('_atom_site_fract_x')\n",
        "            ys = block.find_values('_atom_site_fract_y')\n",
        "            zs = block.find_values('_atom_site_fract_z')\n",
        "            is_cartesian = False\n",
        "        if not xs or not ys or not zs:\n",
        "            xs = block.find_values('_atom_site.fract_x')\n",
        "            ys = block.find_values('_atom_site.fract_y')\n",
        "            zs = block.find_values('_atom_site.fract_z')\n",
        "            is_cartesian = False\n",
        "        if not xs or not ys or not zs:\n",
        "            raise RuntimeError(f\"Could not find matching x, y, z coordinate tags in {path}\")\n",
        "        if not (len(xs) == len(ys) == len(zs)):\n",
        "             raise RuntimeError(f\"Coordinate column mismatch in {path}: len(x)={len(xs)}, len(y)={len(ys)}, len(z)={len(zs)}\")\n",
        "        if len(xs) < 2:\n",
        "            raise RuntimeError(f\"Found coordinate tags, but < 2 atoms in {path}\")\n",
        "        cell = None\n",
        "        if not is_cartesian:\n",
        "            try:\n",
        "                doc_small = gemmi.read_small_structure(path)\n",
        "                cell = doc_small.cell\n",
        "                if not (cell.a and cell.b and cell.c):\n",
        "                     raise RuntimeError(\"Cell parameters are incomplete or zero.\")\n",
        "            except Exception as e:\n",
        "                try:\n",
        "                    st = gemmi.read_structure(path)\n",
        "                    cell = st.cell\n",
        "                    if not (cell.a and cell.b and cell.c):\n",
        "                         raise RuntimeError(\"Cell parameters are incomplete or zero (from read_structure).\")\n",
        "                except Exception as e2:\n",
        "                     raise RuntimeError(f\"CIF has fractional coords but cell is invalid. small_structure err: {e}; read_structure err: {e2}\")\n",
        "        coords = []\n",
        "        for i in range(2):\n",
        "            try:\n",
        "                x = float(xs[i])\n",
        "                y = float(ys[i])\n",
        "                z = float(zs[i])\n",
        "            except ValueError:\n",
        "                print(f\"[Warning] Skipping non-numeric coordinate value in {path} at row {i}\")\n",
        "                continue\n",
        "            if is_cartesian:\n",
        "                coords.append([x, y, z])\n",
        "            else:\n",
        "                pos = cell.orthogonalize(gemmi.Fractional(x, y, z))\n",
        "                coords.append([pos.x, pos.y, pos.z])\n",
        "        if len(coords) < 2:\n",
        "            raise RuntimeError(f\"Could not parse at least 2 valid numeric atoms in {path}\")\n",
        "        return np.array(coords, dtype=np.float64)\n",
        "    except Exception as e:\n",
        "        print(f\"[FATAL] Error parsing CIF {path}: {e}\", file=sys.stderr)\n",
        "        raise\n",
        "\n",
        "def load_and_align_geometries(paths: list):\n",
        "    \"\"\"\n",
        "    --- v5.4: BOND AXIS ALIGNMENT FIX ---\n",
        "    Loads CIFs, gets O-O distance 'd', and stores a\n",
        "    standardized, Z-axis-aligned geometry: [[0,0,-d/2], [0,0,d/2]].\n",
        "    This fixes all \"phantom dip\" interpolation artifacts.\n",
        "    \"\"\"\n",
        "    if len(paths) < 2:\n",
        "        raise ValueError(\"Must provide at least two CIF paths to morph between.\")\n",
        "\n",
        "    aligned_coords_list = []\n",
        "\n",
        "    print(\"[Geo] Loading Oâ€“O Pair Distances and creating standardized geometries...\")\n",
        "    for i, path in enumerate(paths):\n",
        "        # 1. Load raw (2,3) coordinates\n",
        "        raw_coords = get_first_two_atom_coords(path)\n",
        "\n",
        "        # 2. Calculate the *only* thing that matters: the distance\n",
        "        dist = np.linalg.norm(raw_coords[0] - raw_coords[1])\n",
        "\n",
        "        if dist < 0.1:\n",
        "            warnings.warn(\n",
        "                f\"File {i} ({os.path.basename(path)}) has O-O distance < 0.1 Ã…. \"\n",
        "                \"Ensure CIF has correct O-O pair as first two atoms.\",\n",
        "                UserWarning\n",
        "            )\n",
        "\n",
        "        # 3. Create the new, standardized geometry aligned to the Z-axis\n",
        "        d_half = dist / 2.0\n",
        "        aligned_geom = np.array([\n",
        "            [0.0, 0.0, -d_half],\n",
        "            [0.0, 0.0,  d_half]\n",
        "        ], dtype=np.float64)\n",
        "\n",
        "        aligned_coords_list.append(aligned_geom)\n",
        "        print(f\"  - File {i} ({os.path.basename(path)}): {dist:.3f} Ã… (Standardized)\")\n",
        "\n",
        "    print(f\"[Geo] Standardization complete. All {len(aligned_coords_list)} geometries now aligned to Z-axis.\")\n",
        "    return aligned_coords_list, 2\n",
        "\n",
        "# ===================================================================\n",
        "# --- SIMULATION & PLOTTING ---\n",
        "# ===================================================================\n",
        "\n",
        "def sigmoid(t, tau_fs, center_fs):\n",
        "    arg = (t - center_fs) / tau_fs\n",
        "    arg = np.clip(arg, -100, 100)\n",
        "    return 1.0 / (1.0 + np.exp(-arg))\n",
        "\n",
        "def mix_coords(X_A, X_B, s):\n",
        "    s = float(s)\n",
        "    # This interpolation now works perfectly, as X_A and X_B\n",
        "    # are both aligned to the Z-axis.\n",
        "    return (1.0 - s) * X_A + s * X_B\n",
        "\n",
        "def calculate_J_metric(s_total, dOO, temp_noise, resonance_center, is_ablation=False):\n",
        "    \"\"\"\n",
        "    --- UPDATED: `resonance_center` is now a parameter ---\n",
        "    \"\"\"\n",
        "    J_noise = temp_noise * 1e-2 + 1e-3\n",
        "\n",
        "    # --- NEW: Resonance peak is centered on the user-defined index ---\n",
        "    resonance_width = 0.5 # The width of the peak (in 's' units)\n",
        "    s_eff = float(s_total)\n",
        "    J_resonance = 1.0 * np.exp(-0.5 * ((s_eff - resonance_center) / resonance_width)**2)\n",
        "    # ---\n",
        "\n",
        "    d_eff = float(dOO)\n",
        "    d_penalty = 1.0 - 2.0 * np.abs(d_eff - 1.46) # Still assumes 1.46 is ideal\n",
        "    d_penalty = np.clip(d_penalty, 0.1, 1.0)\n",
        "\n",
        "    if is_ablation:\n",
        "        J_metric = J_noise\n",
        "    else:\n",
        "        J_metric = (J_resonance * d_penalty) + J_noise\n",
        "    return float(J_metric)\n",
        "\n",
        "def run_tdse_like(geoms_list, T_K: float, dt_fs=0.5, steps=40000,\n",
        "                  tau_fs=3500.0, center_fs=7000.0,\n",
        "                  temp_noise_scale=0.1, rng_seed=42,\n",
        "                  resonance_center=1.0, is_ablation=False):\n",
        "    \"\"\"\n",
        "    --- UPDATED: Runs an N-state simulation ---\n",
        "    geoms_list is now a *list* of (2,3) arrays, moved to GPU.\n",
        "    \"\"\"\n",
        "    num_geoms = len(geoms_list)\n",
        "    num_segments = num_geoms - 1\n",
        "    if num_segments < 1:\n",
        "        raise ValueError(\"geoms_list must contain at least 2 geometries.\")\n",
        "\n",
        "    rng = np.random.default_rng(int(rng_seed + T_K))\n",
        "    kT_rel = (T_K / 300.0)\n",
        "\n",
        "    t_list, s_list, J_list, d_list = [], [], [], []\n",
        "    X_curr_gpu = xp.zeros((2, 3), dtype=xp.float64) # This will be cupy or numpy\n",
        "\n",
        "    for step in range(steps + 1):\n",
        "        t_fs = step * dt_fs\n",
        "\n",
        "        # 1. Morphing state\n",
        "        # s_total now goes from 0 -> num_segments (e.g., 0 -> 8 for 9 files)\n",
        "        s_total_unclipped = num_segments * sigmoid(t_fs, tau_fs, center_fs)\n",
        "        s_total = np.clip(s_total_unclipped, 0.0, num_segments)\n",
        "\n",
        "        # 2. Geometry\n",
        "        # Find which segment we are in\n",
        "        # We must clamp the index to be N-2 (the start of the *last* segment)\n",
        "        segment_index = min(int(s_total), num_segments - 1)\n",
        "\n",
        "        # Find how \"far\" we are into that segment\n",
        "        s_local = s_total - segment_index # This will be 0.0 -> 1.0\n",
        "\n",
        "        # Get the two geometries for this segment\n",
        "        # geoms_list is now ALIGNED and on the GPU (or is just numpy)\n",
        "        X_A = geoms_list[segment_index]\n",
        "        X_B = geoms_list[segment_index + 1]\n",
        "\n",
        "        X_curr_gpu = mix_coords(X_A, X_B, s_local)\n",
        "\n",
        "        # Because X_A and X_B are aligned, this calculation\n",
        "        # will no longer produce \"phantom dips\".\n",
        "        dOO_gpu = xp.linalg.norm(X_curr_gpu[0] - X_curr_gpu[1])\n",
        "\n",
        "        # This line correctly handles both cases:\n",
        "        # - If GPU_ON, dOO_gpu is cupy.array, .get() moves it to CPU\n",
        "        # - If not GPU_ON, dOO_gpu is numpy.float64, no .get() needed\n",
        "        dOO = float(dOO_gpu.get() if GPU_ON else dOO_gpu)\n",
        "\n",
        "        # 3. Physics (J metric)\n",
        "        temp_noise = (\n",
        "            temp_noise_scale * kT_rel * (rng.random(1, dtype=np.float64)[0] - 0.5)\n",
        "        )\n",
        "\n",
        "        J_val = calculate_J_metric(s_total, dOO, temp_noise,\n",
        "                                   resonance_center=resonance_center,\n",
        "                                   is_ablation=is_ablation)\n",
        "        t_list.append(t_fs)\n",
        "        s_list.append(s_total)\n",
        "        J_list.append(J_val)\n",
        "        d_list.append(dOO)\n",
        "\n",
        "    return (np.array(t_list), np.array(s_list),\n",
        "            np.array(J_list), np.array(d_list))\n",
        "\n",
        "def cdf_series(x: np.ndarray):\n",
        "    x_cpu = x[~np.isnan(x)]\n",
        "    if x_cpu.size == 0:\n",
        "        return np.array([]), np.array([])\n",
        "    xs = np.sort(x_cpu)\n",
        "    cdf = np.arange(1, xs.size + 1) / xs.size\n",
        "    return xs, cdf\n",
        "\n",
        "def plot_timeseries(t, J, s, d, title, path):\n",
        "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "    ax1.set_xlabel(\"t (fs)\")\n",
        "    ax1.set_ylabel(\"J / s\")\n",
        "    ax1.plot(t, J, label=\"J (metric)\", lw=2)\n",
        "    ax1.plot(t, s, label=\"s_total (morph)\", ls=\"--\", color=\"tab:orange\")\n",
        "    ax1.legend(loc=\"upper left\")\n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.set_ylabel(\"d(O-O) [Ã…]\")\n",
        "    ax2.plot(t, d, label=\"d(O-O) [Ã…]\", color=\"tab:green\", lw=2)\n",
        "\n",
        "    # --- v5.5 TWEAK: Set Y-axis to requested hard-coded limits ---\n",
        "    ax2.set_ylim(1.455, 1.465)\n",
        "    # ---\n",
        "\n",
        "    ax2.legend(loc=\"upper center\")\n",
        "    plt.title(title)\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(path, dpi=200)\n",
        "    plt.close(fig)\n",
        "\n",
        "def plot_arrhenius(df, run_id, path):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    finite = df.dropna(subset=[\"invT\", \"ln_J\"])\n",
        "    if len(finite) >= 2:\n",
        "        x = finite[\"invT\"].values\n",
        "        y = finite[\"ln_J\"].values\n",
        "        A = np.vstack([x, np.ones_like(x)]).T\n",
        "        slope, intercept = np.linalg.lstsq(A, y, rcond=None)[0]\n",
        "        yfit = slope * x + intercept\n",
        "        Ea_over_k = -slope\n",
        "        plt.plot(x, y, \"o\", ms=8, label=\"Data (mean of tail)\")\n",
        "        plt.plot(x, yfit, \"-\", lw=2, label=f\"Fit: -Ea/k = {Ea_over_k:.2f} K\")\n",
        "    plt.xlabel(\"1/T (Kâ»Â¹)\")\n",
        "    plt.ylabel(\"ln (J_metric) (a.u.)\")\n",
        "    plt.title(f\"Arrhenius Plot â€” RUN_ID={run_id}\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "# ===================================================================\n",
        "# --- FILE MANAGEMENT & HASHING ---\n",
        "# ===================================================================\n",
        "\n",
        "def get_hashes_of(path: str) -> dict:\n",
        "    h_256 = hashlib.sha256()\n",
        "    h_512 = hashlib.sha512()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1 << 20), b\"\"):\n",
        "            h_256.update(chunk)\n",
        "            h_512.update(chunk)\n",
        "    return {\"sha256\": h_256.hexdigest(), \"sha512\": h_512.hexdigest()}\n",
        "\n",
        "def get_hashes_of_bytes(data: bytes) -> dict:\n",
        "    h_256 = hashlib.sha256(data)\n",
        "    h_512 = hashlib.sha512(data)\n",
        "    return {\"sha256\": h_256.hexdigest(), \"sha512\": h_512.hexdigest()}\n",
        "\n",
        "def compute_run_id(cif_paths, params_dict) -> str:\n",
        "    h = hashlib.sha256()\n",
        "    h.update(CODE_VERSION.encode())\n",
        "    for p in cif_paths:\n",
        "        h.update(os.path.basename(p).encode())\n",
        "        h.update(get_hashes_of(p)[\"sha256\"].encode())\n",
        "    h.update(json.dumps(params_dict, sort_keys=True).encode())\n",
        "    return h.hexdigest()[:16]\n",
        "\n",
        "def write_csv(path, t, s, J, d, header_comment):\n",
        "    with open(path, \"w\") as f:\n",
        "        f.write(header_comment + \"\\n\")\n",
        "        f.write(\"t_fs,s_total,J_metric,d_OO\\n\")\n",
        "        for i in range(len(t)):\n",
        "            f.write(f\"{t[i]:.1f},{s[i]:.6f},{J[i]:.6f},{d[i]:.6f}\\n\")\n",
        "\n",
        "def write_cdf_csv(path, x, cdf):\n",
        "    with open(path, \"w\") as f:\n",
        "        f.write(\"value,cdf\\n\")\n",
        "        for i in range(len(x)):\n",
        "            f.write(f\"{x[i]:.6f},{cdf[i]:.6f}\\n\")\n",
        "\n",
        "# ===================================================================\n",
        "# --- MAIN EXECUTION ---\n",
        "# ===================================================================\n",
        "\n",
        "def main():\n",
        "\n",
        "    script_path = os.path.abspath(sys.argv[0])\n",
        "\n",
        "    ap = argparse.ArgumentParser(description=f\"GQR-XIV Veracity Run ({CODE_VERSION})\")\n",
        "\n",
        "    # --- UPDATED: nargs='+' accepts 1 or more CIFs (we check for 2+ later) ---\n",
        "    ap.add_argument(\"--cifs\", nargs='+', required=True, help=\"Two or more CIF files for the morph sequence (e.g., D E F G H I J K)\")\n",
        "    # ---\n",
        "\n",
        "    # --- v5.6 FIX: Corrected typo 'add_add_argument' to 'add_argument' ---\n",
        "    ap.add_argument(\"--temps\", nargs=\"+\", type=int, default=[285, 295, 305, 315, 325], help=\"List of temperatures (K) to run\")\n",
        "    # ---\n",
        "\n",
        "    ap.add_argument(\"--steps\", type=int, default=40000, help=\"Number of simulation steps\")\n",
        "    ap.add_argument(\"--dtfs\", type=float, default=0.5, help=\"Timestep (fs)\")\n",
        "    ap.add_argument(\"--seed\", type=int, default=42, help=\"Base RNG seed\")\n",
        "    ap.add_argument(\"--tau_fs\", type=float, default=3500.0, help=\"Sigmoid tau (width) in fs\")\n",
        "    ap.add_argument(\"--center_fs\", type=float, default=7000.0, help=\"Sigmoid center in fs\")\n",
        "    ap.add_argument(\"--temp_noise_scale\", type=float, default=0.1, help=\"Scalar for temperature noise effect\")\n",
        "\n",
        "    # --- NEW: Define the resonance center ---\n",
        "    # --- Grabs the default value from the TWEAKABLE PARAMETER at the top ---\n",
        "    ap.add_argument(\"--resonance-center\", type=float, default=DEFAULT_RESONANCE_CENTER, help=\"The 's_total' index (0-based) for the J metric resonance peak.\")\n",
        "    # ---\n",
        "\n",
        "    ap.add_argument(\"--run-ablation\", action=\"store_true\", help=\"Run ablation (null hypothesis) test\")\n",
        "\n",
        "    args, unknown = ap.parse_known_args()\n",
        "\n",
        "    # --- Handle CIFs ---\n",
        "    if len(args.cifs) < 2:\n",
        "        print(\"[FATAL] --cifs requires at least 2 files to run a simulation.\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # --- Load Geometries ---\n",
        "    try:\n",
        "        # geoms is now a list of (2,3) arrays, ALL ALIGNED to Z-axis\n",
        "        geoms_cpu, atoms_unified = load_and_align_geometries(args.cifs)\n",
        "        # Move all geometries to GPU *once* if we are using it\n",
        "        # If GPU_ON is False, xp is numpy, so this just creates numpy arrays\n",
        "        geoms_list_gpu = [xp.asarray(g, dtype=xp.float64) for g in geoms_cpu]\n",
        "    except Exception as e:\n",
        "        print(f\"[FATAL] Error loading geometries: {e}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # --- Define Run ID and Parameters ---\n",
        "    params = dict(\n",
        "        cifs=[os.path.basename(p) for p in args.cifs],\n",
        "        temps_K=args.temps,\n",
        "        steps=args.steps,\n",
        "        dt_fs=args.dtfs,\n",
        "        seed=args.seed,\n",
        "        tau_fs=args.tau_fs,\n",
        "        center_fs=args.center_fs,\n",
        "        temp_noise_scale=args.temp_noise_scale,\n",
        "        atoms_unified=atoms_unified,\n",
        "        code_version=CODE_VERSION,\n",
        "        gpu_on=GPU_ON, # This will now be correctly False on CPU-only machines\n",
        "        is_ablation=args.run_ablation,\n",
        "        resonance_center=args.resonance_center # <-- NEWLY TRACKED\n",
        "    )\n",
        "    RUN_ID = compute_run_id(args.cifs, params)\n",
        "\n",
        "    run_type = \"GPU\" if GPU_ON else \"CPU\"\n",
        "    run_mode = \"ABLATION\" if args.run_ablation else \"veracity\"\n",
        "\n",
        "    print(f\"[INIT] RUN_ID = {RUN_ID} (GPU={GPU_ON}) -- {run_type} {run_mode.upper()} RUN\")\n",
        "    run_prefix = f\"GQR14_{run_type}_{run_mode}\"\n",
        "\n",
        "    # --- Setup Output Directories ---\n",
        "    root_dir = f\"{run_prefix}_{RUN_ID}\"\n",
        "    runs_d = os.path.join(root_dir, \"runs\")       # Raw timeseries CSVs\n",
        "    der_d = os.path.join(root_dir, \"derived\")     # CDFs, Arrhenius table\n",
        "    plot_d = os.path.join(root_dir, \"plots\")      # PNGs\n",
        "    os.makedirs(runs_d, exist_ok=True)\n",
        "    os.makedirs(der_d, exist_ok=True)\n",
        "    os.makedirs(plot_d, exist_ok=True)\n",
        "\n",
        "    file_manifest = []\n",
        "    arrhenius_data = []\n",
        "\n",
        "    # --- Main Simulation Loop (per temperature) ---\n",
        "    for T in args.temps:\n",
        "        print(f\"[Sim] Running T = {T} K...\")\n",
        "        t, s, J, d = run_tdse_like(\n",
        "            geoms_list_gpu, T,\n",
        "            dt_fs=args.dtfs, steps=args.steps,\n",
        "            tau_fs=args.tau_fs, center_fs=args.center_fs,\n",
        "            temp_noise_scale=args.temp_noise_scale,\n",
        "            rng_seed=args.seed,\n",
        "            resonance_center=args.resonance_center, # Pass it down\n",
        "            is_ablation=args.run_ablation\n",
        "        )\n",
        "\n",
        "        # --- Save Raw Timeseries CSV ---\n",
        "        base_name = f\"HIJ_T{T}K_{RUN_ID}\" # Kept old base name for compatibility\n",
        "        csv_path = os.path.join(runs_d, f\"{base_name}_timeseries.csv\")\n",
        "        csv_header = f\"# RUN_ID={RUN_ID} T_K={T} ABLATION={args.run_ablation}\"\n",
        "        write_csv(csv_path, t, s, J, d, csv_header)\n",
        "        file_manifest.append(csv_path)\n",
        "\n",
        "        # --- Save Timeseries Plot ---\n",
        "        plot_path = os.path.join(plot_d, f\"{base_name}_timeseries.png\")\n",
        "        plot_title = f\"{os.path.basename(root_dir)} (T={T}K)\"\n",
        "        plot_timeseries(t, J, s, d, plot_title, plot_path)\n",
        "        file_manifest.append(plot_path)\n",
        "\n",
        "        # --- Save CDFs ---\n",
        "        cdf_J_x, cdf_J_y = cdf_series(J)\n",
        "        cdf_d_x, cdf_d_y = cdf_series(d)\n",
        "\n",
        "        cdf_J_path = os.path.join(der_d, f\"{base_name}_cdf_J.csv\")\n",
        "        cdf_d_path = os.path.join(der_d, f\"{base_name}_cdf_d.csv\")\n",
        "\n",
        "        write_cdf_csv(cdf_J_path, cdf_J_x, cdf_J_y)\n",
        "        write_cdf_csv(cdf_d_path, cdf_d_x, cdf_d_y)\n",
        "        file_manifest.append(cdf_J_path)\n",
        "        file_manifest.append(cdf_d_path)\n",
        "\n",
        "        # --- Collect Arrhenius Data (from tail) ---\n",
        "        tail_start = int(0.8 * args.steps) # Use last 20%\n",
        "        J_tail_mean = float(np.mean(J[tail_start:]))\n",
        "\n",
        "        arrhenius_data.append({\n",
        "            \"T_K\": T,\n",
        "            \"invT\": 1.0 / T,\n",
        "            \"J_mean_tail\": J_tail_mean,\n",
        "            \"ln_J\": np.log(J_tail_mean) if J_tail_mean > 0 else np.nan,\n",
        "        })\n",
        "\n",
        "    # --- Process and Save Arrhenius Data ---\n",
        "    arr_df = pd.DataFrame(arrhenius_data)\n",
        "    arr_csv_path = os.path.join(der_d, f\"arrhenius_table_{RUN_ID}.csv\")\n",
        "    arr_df.to_csv(arr_csv_path, index=False)\n",
        "    file_manifest.append(arr_csv_path)\n",
        "\n",
        "    arr_plot_path = os.path.join(plot_d, f\"arrhenius_plot_{RUN_ID}.png\")\n",
        "    plot_arrhenius(arr_df, RUN_ID, arr_plot_path)\n",
        "    file_manifest.append(arr_plot_path)\n",
        "\n",
        "    # --- Create Final Manifest JSON (with DUAL HASHES) ---\n",
        "    print(f\"[Packaging] Generating dual-hash manifest...\")\n",
        "    script_hashes = get_hashes_of(script_path)\n",
        "\n",
        "    manifest_content = {\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"run_prefix\": run_prefix,\n",
        "        \"is_ablation_run\": args.run_ablation,\n",
        "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
        "        \"parameters\": params,\n",
        "        \"run_script\": {\n",
        "            \"file\": os.path.basename(script_path),\n",
        "            **script_hashes\n",
        "        },\n",
        "        \"cif_hashes\": [\n",
        "            dict(\n",
        "                file=os.path.basename(p),\n",
        "                **get_hashes_of(p)\n",
        "            ) for p in args.cifs\n",
        "        ],\n",
        "        \"files\": []\n",
        "    }\n",
        "\n",
        "    for p in file_manifest:\n",
        "        file_hashes = get_hashes_of(p)\n",
        "        manifest_content[\"files\"].append({\n",
        "            \"file\": os.path.relpath(p, root_dir),\n",
        "            \"bytes\": os.path.getsize(p),\n",
        "            **file_hashes\n",
        "        })\n",
        "\n",
        "    manifest_path = os.path.join(root_dir, f\"manifest_{RUN_ID}.json\")\n",
        "    with open(manifest_path, \"w\") as f:\n",
        "        json.dump(manifest_content, f, indent=2)\n",
        "\n",
        "    # --- Create Final ZIP Bundle ---\n",
        "    zip_path = f\"{root_dir}.zip\"\n",
        "    print(f\"[Packaging] Creating {zip_path}...\")\n",
        "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "        # 1. Write the manifest\n",
        "        zf.write(manifest_path, arcname=os.path.basename(manifest_path))\n",
        "\n",
        "        # 2. Write the script\n",
        "        zf.write(script_path, arcname=os.path.basename(script_path))\n",
        "\n",
        "        # 3. Write all the output files (CSVs, PNGs)\n",
        "        for p in file_manifest:\n",
        "            zf.write(p, arcname=os.path.relpath(p, root_dir))\n",
        "\n",
        "        # 4. --- NEW: Write the input CIF files ---\n",
        "        print(f\"[Packaging] Adding {len(args.cifs)} input CIFs to ZIP...\")\n",
        "        cif_dir_arcname = \"cifs\" # The folder name inside the ZIP\n",
        "        for cif_path in args.cifs:\n",
        "            # Check if file exists before trying to add it\n",
        "            if os.path.exists(cif_path):\n",
        "                cif_basename = os.path.basename(cif_path)\n",
        "                # Create the full path inside the zip file, e.g., \"cifs/8F4D.cif\"\n",
        "                arc_path = os.path.join(cif_dir_arcname, cif_basename)\n",
        "                zf.write(cif_path, arcname=arc_path)\n",
        "            else:\n",
        "                print(f\"[Warning] Could not find input CIF to bundle: {cif_path}\", file=sys.stderr)\n",
        "\n",
        "    print(f\"[SUCCESS] Wrote {zip_path} (RUN_ID={RUN_ID})\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s7VHDnJRWHUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EpVR0zswaTij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e1b7e6-36cc-40a1-946b-37dbfadd6dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gqr14_make_veracity_zip_v5.6_aligned.py --cifs 8F4C.cif 8F4D.cif 8F4E.cif 8F4F.cif 8F4G.cif 8F4H.cif 8F4I.cif 8F4J.cif 8F4K.cif\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb7D8M7qZxaj",
        "outputId": "d79fdfdd-c518-41ee-ee96-e7cdffd8c829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Warning] GPU check failed unexpectedly (cudaErrorInsufficientDriver: CUDA driver version is insufficient for CUDA runtime version). Falling back to CPU.\n",
            "[Geo] Loading Oâ€“O Pair Distances and creating standardized geometries...\n",
            "  - File 0 (8F4C.cif): 1.458 Ã… (Standardized)\n",
            "  - File 1 (8F4D.cif): 1.458 Ã… (Standardized)\n",
            "  - File 2 (8F4E.cif): 1.459 Ã… (Standardized)\n",
            "  - File 3 (8F4F.cif): 1.458 Ã… (Standardized)\n",
            "  - File 4 (8F4G.cif): 1.458 Ã… (Standardized)\n",
            "  - File 5 (8F4H.cif): 1.459 Ã… (Standardized)\n",
            "  - File 6 (8F4I.cif): 1.458 Ã… (Standardized)\n",
            "  - File 7 (8F4J.cif): 1.460 Ã… (Standardized)\n",
            "  - File 8 (8F4K.cif): 1.456 Ã… (Standardized)\n",
            "[Geo] Standardization complete. All 9 geometries now aligned to Z-axis.\n",
            "[INIT] RUN_ID = f28feebea285f5d6 (GPU=False) -- CPU VERACITY RUN\n",
            "[Sim] Running T = 285 K...\n",
            "[Sim] Running T = 295 K...\n",
            "[Sim] Running T = 305 K...\n",
            "[Sim] Running T = 315 K...\n",
            "[Sim] Running T = 325 K...\n",
            "[Packaging] Generating dual-hash manifest...\n",
            "[Packaging] Creating GQR14_CPU_veracity_f28feebea285f5d6.zip...\n",
            "[Packaging] Adding 9 input CIFs to ZIP...\n",
            "[SUCCESS] Wrote GQR14_CPU_veracity_f28feebea285f5d6.zip (RUN_ID=f28feebea285f5d6)\n"
          ]
        }
      ]
    }
  ]
}