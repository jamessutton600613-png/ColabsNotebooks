{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamessutton600613-png/GC/blob/main/Untitled264.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S0ptjFVLIfEm",
        "outputId": "4f7566da-d4b9-45df-b443-aa1466735b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: cupy-cuda11x 13.6.0\n",
            "Uninstalling cupy-cuda11x-13.6.0:\n",
            "  Successfully uninstalled cupy-cuda11x-13.6.0\n",
            "Found existing installation: cupy-cuda12x 13.6.0\n",
            "Uninstalling cupy-cuda12x-13.6.0:\n",
            "  Successfully uninstalled cupy-cuda12x-13.6.0\n"
          ]
        }
      ],
      "source": [
        "# 1. Clean the environment and install core libraries\n",
        "!pip install -q gemmi pyscf\n",
        "\n",
        "# 2. Re-install CuPy (Force clean install of the core dependency)\n",
        "!pip uninstall -y cupy-cuda11x cupy-cuda12x # Ensure cleanup\n",
        "!pip install -q cupy-cuda12x # Install the modern, clean version\n",
        "\n",
        "# 3. Disable verbose GPU warnings that slow down the run\n",
        "import os\n",
        "os.environ['CUPY_PACKAGE_NAME'] = 'cupy'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jqxHB0kRI4aW",
        "outputId": "724fa0cc-50d7-42fb-a69a-c121154f7b0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Working directory: /content/gqr_fe4s4_ispG\n",
            "Collecting cupy-cuda11x\n",
            "  Using cached cupy_cuda11x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: numpy<2.6,>=1.22 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda11x) (2.0.2)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda11x) (0.8.3)\n",
            "Using cached cupy_cuda11x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl (99.7 MB)\n",
            "Installing collected packages: cupy-cuda11x\n",
            "Successfully installed cupy-cuda11x-13.6.0\n",
            "\n",
            "========================================\n",
            "=== STARTING CURVATURE RUN (def2-svp) ===\n",
            "========================================\n",
            " [Loader] Reading /content/gqr_fe4s4_ispG/4s39.cif...\n",
            " Extracted 8 atoms and centered geometry.\n",
            " [Loader] Reading /content/gqr_fe4s4_ispG/4s3e.cif...\n",
            " Extracted 8 atoms and centered geometry.\n",
            "\n",
            "--- Processing Active Cluster (4S39) ---\n",
            " [Calc] Running DFT (def2-svp) for Active Base...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/cupy/_environment.py:596: UserWarning: \n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  CuPy may not function correctly because multiple CuPy packages are installed\n",
            "  in your environment:\n",
            "\n",
            "    cupy-cuda11x, cupy-cuda12x\n",
            "\n",
            "  Follow these steps to resolve this issue:\n",
            "\n",
            "    1. For all packages listed above, run the following command to remove all\n",
            "       existing CuPy installations:\n",
            "\n",
            "         $ pip uninstall <package_name>\n",
            "\n",
            "      If you previously installed CuPy via conda, also run the following:\n",
            "\n",
            "         $ conda uninstall cupy\n",
            "\n",
            "    2. Install the appropriate CuPy package.\n",
            "       Refer to the Installation Guide for detailed instructions.\n",
            "\n",
            "         https://docs.cupy.dev/en/stable/install.html\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  warnings.warn(f'''\n",
            "/usr/local/lib/python3.12/dist-packages/gpu4pyscf/lib/cutensor.py:158: UserWarning: using cupy as the tensor contraction engine.\n",
            "  warnings.warn(f'using {contract_engine} as the tensor contraction engine.')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Library gpu4pyscf not found. You can install this package via\n",
            "    pip install gpu4pyscf-cuda11x\n",
            "See more installation info at https://github.com/pyscf/gpu4pyscf\n",
            " [WARNING] GPU acceleration failed (libcublas.so.11: cannot open shared object file: No such file or directory). Reverting to CPU.\n",
            " [!] DIIS failed. Switching to Newton-Raphson solver via mf.newton()...\n",
            " [Success] SCF Converged with NR (E=-6645.0998 Ha)\n",
            "\n",
            "CRITICAL FAILURE DURING SETUP: not enough values to unpack (expected 2, got 1)\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# ==============================================================================\n",
        "# Fe4S4 CURVATURE TRAP PIPELINE - STABLE VERSION (WITH GPU ACCELERATION)\n",
        "# ==============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "import gemmi\n",
        "\n",
        "# PySCF Imports: Relying on base modules + to_gpu() method\n",
        "from pyscf import gto, dft\n",
        "from pyscf.dft import numint\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1. CONFIGURATION (Unchanged)\n",
        "# ------------------------------------------\n",
        "BASIS_SET = 'def2-svp'\n",
        "FUNCTIONAL = 'pbe'\n",
        "GRID_POINTS = 32\n",
        "BOX_MARGIN = 3.5\n",
        "DISPLACEMENT = 0.20\n",
        "DIIS_MAX_CYCLE = 50\n",
        "CONV_TOL = 1e-5\n",
        "L_EFF = 3.0\n",
        "BINS_LIST = list(range(1, 126, 1))\n",
        "\n",
        "# Setup environment\n",
        "project_root = \"/content/gqr_fe4s4_ispG\"\n",
        "os.makedirs(project_root, exist_ok=True)\n",
        "os.chdir(project_root)\n",
        "print(\"Working directory:\", os.getcwd())\n",
        "\n",
        "# ------------------------------------------\n",
        "# 2. CLASS: STRUCTURE EXTRACTOR (Unchanged)\n",
        "# ------------------------------------------\n",
        "class FeS_Analyzer:\n",
        "    def __init__(self, cif_path):\n",
        "        self.cif_path = cif_path\n",
        "        try:\n",
        "            self.structure = gemmi.read_structure(cif_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading CIF: {e}\")\n",
        "            sys.exit(1)\n",
        "        self.model = self.structure[0]\n",
        "        self.atoms = []\n",
        "\n",
        "    def extract_cluster(self, residue_name=\"SF4\"):\n",
        "        print(f\" [Loader] Reading {self.cif_path}...\")\n",
        "        cluster_atoms = []\n",
        "\n",
        "        for chain in self.model:\n",
        "            for res in chain:\n",
        "                if residue_name in res.name:\n",
        "                    for atom in res:\n",
        "                        pos = atom.pos\n",
        "                        cluster_atoms.append({\n",
        "                            'elem': atom.element.name,\n",
        "                            'pos': np.array([pos.x, pos.y, pos.z])\n",
        "                        })\n",
        "\n",
        "        if not cluster_atoms:\n",
        "            raise ValueError(f\"Cluster extraction failed: '{residue_name}' not found.\")\n",
        "\n",
        "        positions = np.array([a['pos'] for a in cluster_atoms])\n",
        "        centroid = np.mean(positions, axis=0)\n",
        "        self.atoms = []\n",
        "        for atom in cluster_atoms:\n",
        "            self.atoms.append((atom['elem'], atom['pos'] - centroid))\n",
        "        print(f\" Extracted {len(self.atoms)} atoms and centered geometry.\")\n",
        "\n",
        "        symbols = np.array([a[0] for a in self.atoms])\n",
        "        coords_centered = np.array([a[1] for a in self.atoms])\n",
        "        return symbols, coords_centered\n",
        "\n",
        "    def apply_mode_b_distortion(self, symbols, coords_centered):\n",
        "        new_positions = coords_centered.copy()\n",
        "        fe_indices = [i for i, s in enumerate(symbols) if s == 'Fe']\n",
        "        s_indices = [i for i, s in enumerate(symbols) if s == 'S']\n",
        "\n",
        "        pairs = []\n",
        "        for fe_idx in fe_indices:\n",
        "            fe_pos = coords_centered[fe_idx]\n",
        "            min_dist = np.inf\n",
        "            nearest_s_idx = -1\n",
        "            for s_idx in s_indices:\n",
        "                dist = np.linalg.norm(fe_pos - coords_centered[s_idx])\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    nearest_s_idx = s_idx\n",
        "            pairs.append((fe_idx, nearest_s_idx))\n",
        "\n",
        "        if len(pairs) < 2:\n",
        "             raise ValueError(\"Not enough Fe atoms for Mode B displacement.\")\n",
        "\n",
        "        def stretch_pair(C, i_fe, i_s, d):\n",
        "            v = C[i_s] - C[i_fe]\n",
        "            L = np.linalg.norm(v)\n",
        "            if L < 1e-6: return C\n",
        "            u = v/L\n",
        "            C[i_fe] -= 0.5 * d * u\n",
        "            C[i_s]  += 0.5 * d * u\n",
        "            return C\n",
        "\n",
        "        stretch_pair(new_positions, pairs[0][0], pairs[0][1], +DISPLACEMENT)\n",
        "        stretch_pair(new_positions, pairs[1][0], pairs[1][1], -DISPLACEMENT)\n",
        "\n",
        "        return new_positions\n",
        "\n",
        "    @staticmethod\n",
        "    def atom_list_to_pyscf_string(symbols, coords):\n",
        "        return \"; \".join([f\"{s} {c[0]:.5f} {c[1]:.5f} {c[2]:.5f}\"\n",
        "                          for s, c in zip(symbols, coords)])\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3. FUNCTION: ROBUST ANALYSIS (GPU-ENABLED)\n",
        "# ------------------------------------------\n",
        "def analyze_and_save(symbols, coords, name, file_tag):\n",
        "    print(f\" [Calc] Running DFT ({BASIS_SET}) for {name}...\")\n",
        "\n",
        "    # 1. Build Molecule\n",
        "    atom_string = FeS_Analyzer.atom_list_to_pyscf_string(symbols, coords)\n",
        "    mol = gto.M(atom=atom_string, basis=BASIS_SET, charge=0, spin=0, verbose=0, unit='Angstrom')\n",
        "    mol.build()\n",
        "\n",
        "    # 2. Initialize and Move to GPU ðŸš€\n",
        "    mf = dft.RKS(mol)\n",
        "    mf.xc = FUNCTIONAL\n",
        "    mf.max_cycle = DIIS_MAX_CYCLE\n",
        "    mf.conv_tol = CONV_TOL\n",
        "\n",
        "    # *** GPU ACCELERATION LINE ***\n",
        "    try:\n",
        "        mf = mf.to_gpu()\n",
        "        print(\" [INFO] GPU acceleration enabled.\")\n",
        "    except Exception as e:\n",
        "        print(f\" [WARNING] GPU acceleration failed ({e}). Reverting to CPU.\")\n",
        "\n",
        "    mf.kernel()\n",
        "\n",
        "    # 3. Fallback: Newton-Raphson if DIIS failed\n",
        "    if not mf.converged:\n",
        "        print(f\" [!] DIIS failed. Switching to Newton-Raphson solver via mf.newton()...\")\n",
        "\n",
        "        # If running on GPU, convert back to CPU before using NR, then convert back.\n",
        "        try:\n",
        "            mf = mf.to_cpu()\n",
        "        except:\n",
        "            pass # Already on CPU or failed conversion\n",
        "\n",
        "        mf = mf.newton()\n",
        "        mf.max_cycle = 100\n",
        "        mf.kernel()\n",
        "\n",
        "        if not mf.converged:\n",
        "            print(f\" [CRITICAL FAILURE] SCF did not converge for {name} with NR. Skipping...\")\n",
        "            return None, None\n",
        "        else:\n",
        "            print(f\" [Success] SCF Converged with NR (E={mf.e_tot:.4f} Ha)\")\n",
        "    else:\n",
        "        print(f\" [Success] SCF Converged (E={mf.e_tot:.4f} Ha)\")\n",
        "\n",
        "    # --- Calculation converged, now perform post-processing (on CPU) ---\n",
        "\n",
        "    # Ensure mf object is on CPU for Numint and NumPy post-processing\n",
        "    try:\n",
        "        if hasattr(mf, 'to_cpu'): mf = mf.to_cpu()\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # 4. Grid & Laplacian Calculation (32k points)\n",
        "    coords_np = mol.atom_coords() # Use NumPy coords\n",
        "    min_c = coords_np.min(axis=0) - BOX_MARGIN\n",
        "    max_c = coords_np.max(axis=0) + BOX_MARGIN\n",
        "    xs = np.linspace(min_c[0], max_c[0], GRID_POINTS)\n",
        "    mx, my, mz = np.meshgrid(xs, xs, xs, indexing='ij')\n",
        "    grid_coords = np.vstack([mx.ravel(), my.ravel(), mz.ravel()]).T\n",
        "\n",
        "    # Calculate Density & Laplacian\n",
        "    ao = mol.eval_gto(\"GTOval_sph\", grid_coords)\n",
        "    rho = dft.numint.eval_rho(mol, ao, mf.make_rdm1(), xctype=FUNCTIONAL)\n",
        "    rho_cube = rho.reshape(GRID_POINTS, GRID_POINTS, GRID_POINTS)\n",
        "\n",
        "    dx = xs[1] - xs[0]\n",
        "    lap = (np.gradient(np.gradient(rho_cube, axis=0), axis=0)/dx**2 +\n",
        "           np.gradient(np.gradient(rho_cube, axis=1), axis=1)/dx**2 +\n",
        "           np.gradient(np.gradient(rho_cube, axis=2), axis=2)/dx**2)\n",
        "    abs_lap = np.abs(lap.ravel())\n",
        "\n",
        "    # 5. Filter & Save Raw Laplacian Data (kappa)\n",
        "    cap = np.percentile(abs_lap, 99.5)\n",
        "    kappa = abs_lap[abs_lap < cap]\n",
        "\n",
        "    outfile = f\"{file_tag}_{BASIS_SET}.npz\"\n",
        "    np.savez_compressed(outfile,\n",
        "                        kappa=kappa,\n",
        "                        symbols=symbols,\n",
        "                        coords=coords)\n",
        "    print(f\" [Saved] -> {outfile} (Raw Laplacian data saved)\")\n",
        "\n",
        "    return kappa, mf\n",
        "\n",
        "# ------------------------------------------\n",
        "# 4. ORCHESTRATOR & EXECUTION (Unchanged)\n",
        "# ------------------------------------------\n",
        "def fetch_pdb_if_missing(pdb_code):\n",
        "    filename = f\"{pdb_code.lower()}.cif\"\n",
        "    if os.path.exists(filename):\n",
        "        return filename\n",
        "\n",
        "    url = f\"https://files.rcsb.org/download/{pdb_code}.cif\"\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "    return filename\n",
        "\n",
        "def generate_delta_teeth_json(kappa_base, kappa_mode, tag):\n",
        "    rows = []\n",
        "    for b in BINS_LIST:\n",
        "        min_k = min(kappa_base.min(), kappa_mode.min())\n",
        "        max_k = max(kappa_base.max(), kappa_mode.max())\n",
        "        edges = np.linspace(min_k, max_k, b + 1)\n",
        "\n",
        "        hist_b, _ = np.histogram(kappa_base, bins=edges, density=True)\n",
        "        hist_m, _ = np.histogram(kappa_mode, bins=edges, density=True)\n",
        "\n",
        "        tb = int(np.sum(hist_b < 1e-9))\n",
        "        tm = int(np.sum(hist_m < 1e-9))\n",
        "\n",
        "        Delta_teeth = tm - tb\n",
        "        Delta_r_A = L_EFF / b\n",
        "\n",
        "        rows.append({\n",
        "            \"bins\": b,\n",
        "            \"Delta_r_A\": Delta_r_A,\n",
        "            \"Delta_teeth\": Delta_teeth\n",
        "        })\n",
        "\n",
        "    json_name = f\"{tag}_DeltaTeeth.json\"\n",
        "    import json\n",
        "    with open(json_name, \"w\") as f:\n",
        "        json.dump(rows, f, indent=2)\n",
        "    print(f\" [Saved] {json_name}\")\n",
        "\n",
        "\n",
        "def run_pipeline(active_path, inhib_path):\n",
        "    print(f\"\\n{'='*40}\\n=== STARTING CURVATURE RUN ({BASIS_SET}) ===\\n{'='*40}\")\n",
        "\n",
        "    act_ana = FeS_Analyzer(active_path)\n",
        "    act_syms, act_coords = act_ana.extract_cluster()\n",
        "    inh_ana = FeS_Analyzer(inhib_path)\n",
        "    inh_syms, inh_coords = inh_ana.extract_cluster()\n",
        "\n",
        "    act_dist_coords = act_ana.apply_mode_b_distortion(act_syms, act_coords)\n",
        "    inh_dist_coords = inh_ana.apply_mode_b_distortion(inh_syms, inh_coords)\n",
        "\n",
        "    print(\"\\n--- Processing Active Cluster (4S39) ---\")\n",
        "    k_act_base, mf1 = analyze_and_save(act_syms, act_coords, \"Active Base\", \"4S39_active_base\")\n",
        "    k_act_dist, mf2 = analyze_and_save(act_syms, act_dist_coords, \"Active Distorted\", \"4S39_active_dist\")\n",
        "\n",
        "    print(\"\\n--- Processing Inhibited Cluster (4S3E) ---\")\n",
        "    k_inh_base, mf3 = analyze_and_save(inh_syms, inh_coords, \"Inhibited Base\", \"4S3E_inhib_base\")\n",
        "    k_inh_dist, mf4 = analyze_and_save(inh_syms, inh_dist_coords, \"Inhibited Distorted\", \"4S3E_inhib_dist\")\n",
        "\n",
        "    print(\"\\n--- Generating Final Data Curves ---\")\n",
        "    if all(k is not None for k in [k_act_base, k_act_dist, k_inh_base, k_inh_dist]):\n",
        "        generate_delta_teeth_json(k_act_base, k_act_dist, \"4S39_Active_Curve\")\n",
        "        generate_delta_teeth_json(k_inh_base, k_inh_dist, \"4S3E_Inhibited_Curve\")\n",
        "\n",
        "        def report_teeth(kappa, bins=200):\n",
        "            hist, _ = np.histogram(kappa, bins=bins, density=True)\n",
        "            return int(np.sum(hist < 1e-9))\n",
        "\n",
        "        t_act_base = report_teeth(k_act_base)\n",
        "        t_act_dist = report_teeth(k_act_dist)\n",
        "        t_inh_base = report_teeth(k_inh_base)\n",
        "        t_inh_dist = report_teeth(k_inh_dist)\n",
        "\n",
        "        delta_act = t_act_dist - t_act_base\n",
        "        delta_inh = t_inh_dist - t_inh_base\n",
        "\n",
        "        print(f\"\\n{'='*40}\")\n",
        "        print(\"SUMMARY (Delta Teeth at ~0.015 A Resolution)\")\n",
        "        print(f\"Active (4S39) Delta: {delta_act}\")\n",
        "        print(f\"Inhibited (4S3E) Delta: {delta_inh}\")\n",
        "        print(f\"{'='*40}\\n[Expected: Delta Active > 0, Delta Inhibited < 0 (Collapse Confirmed)]\")\n",
        "    else:\n",
        "        print(\"\\n*** ERROR: Failed to generate final curves due to critical SCF failure. ***\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if 'google.colab' in sys.modules:\n",
        "        # Install GPU-enabled PySCF (Requires GPU runtime)\n",
        "        !pip install -q gemmi pyscf\n",
        "        # It's essential to install cupy and other GPU dependencies for PySCF to work fully.\n",
        "        # This part assumes a standard Colab GPU runtime which has CUDA pre-installed.\n",
        "        !pip install cupy-cuda11x # Install compatible CuPy for PySCF GPU acceleration\n",
        "\n",
        "    try:\n",
        "        p_active = fetch_pdb_if_missing(\"4S39\")\n",
        "        p_inhib = fetch_pdb_if_missing(\"4S3E\")\n",
        "\n",
        "        run_pipeline(os.path.abspath(p_active), os.path.abspath(p_inhib))\n",
        "    except Exception as e:\n",
        "        print(f\"\\nCRITICAL FAILURE DURING SETUP: {e}\")\n",
        "\n",
        "#The video [Specifying GEOMETRY of MOLECULE in PySCF [TUTORIAL #3]](https://www.youtube.com/watch?v=1Eyz-iPykDs) demonstrates how to correctly input molecular geometry strings into PySCF, which is a foundational step in your pipeline.\n",
        "#http://googleusercontent.com/youtube_content/0 *YouTube video views will be stored in your YouTube History, and your data will be stored and used by YouTube according to its [Terms of Service](https://www.youtube.com/static?template=terms)*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e9z_1wxdKBZI",
        "outputId": "4e566f41-1671-4f54-d076-b37ccb6d65f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m386.0/386.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m164.1/164.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gpu4pyscf-cuda12x (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# This uses the repository URL which sometimes bypasses build issues\n",
        "!pip install -q git+https://github.com/pyscf/gpu4pyscf.git\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtr9z++T8Kwf7UG777rj4i",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}