{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamessutton600613-png/GC/blob/main/Untitled287.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE5p_P954wGv",
        "outputId": "976d072e-a14a-4363-dc8c-182f9fc9f7ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "progress: 406/9600 ( 4.2%) elapsed=  10.0s\n",
            "progress: 943/9600 ( 9.8%) elapsed=  20.0s\n",
            "progress: 1670/9600 (17.4%) elapsed=  30.0s\n",
            "progress: 2268/9600 (23.6%) elapsed=  40.1s\n",
            "progress: 2889/9600 (30.1%) elapsed=  50.1s\n",
            "progress: 3616/9600 (37.7%) elapsed=  60.1s\n",
            "progress: 4222/9600 (44.0%) elapsed=  70.1s\n",
            "progress: 4959/9600 (51.7%) elapsed=  80.1s\n",
            "progress: 5612/9600 (58.5%) elapsed=  90.1s\n",
            "progress: 6189/9600 (64.5%) elapsed= 100.1s\n",
            "progress: 6930/9600 (72.2%) elapsed= 110.1s\n",
            "progress: 7573/9600 (78.9%) elapsed= 120.2s\n",
            "progress: 8297/9600 (86.4%) elapsed= 130.2s\n",
            "progress: 9058/9600 (94.4%) elapsed= 140.2s\n",
            "progress: 9494/9600 (98.9%) elapsed= 150.2s\n",
            "Saved NPZ: enz_governance_sweep_npz_only.npz\n",
            "rows shape: (9600, 37)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# ============================================================\n",
        "# SWEEP CONFIG (RANGES)\n",
        "# ============================================================\n",
        "\n",
        "RANGES = {\n",
        "    # Core scale\n",
        "    \"N_PATHS_LIST\": np.array([10, 20, 50, 100, 200, 500, 1000], dtype=int),\n",
        "\n",
        "    # Thermodynamic sensitivity\n",
        "    \"BETA_LIST\": np.array([0.8, 1.2, 1.8, 2.2, 3.0, 4.0], dtype=float),\n",
        "\n",
        "    # Disorder\n",
        "    \"DISORDER_JUMP_LIST\": np.array([0.0, 0.1, 0.2, 0.3, 0.5, 0.7], dtype=float),\n",
        "    \"SHOCK_MODE_LIST\": np.array([0, 1, 2], dtype=int),  # 0: none, 1: one shock @25%, 2: shocks @25% and @60%\n",
        "\n",
        "    # GQR controls\n",
        "    \"GQR_FILTER_BASE_LIST\": np.array([0.4, 0.6, 0.75, 0.9, 0.97], dtype=float),\n",
        "    \"GQR_FILTER_COST_LIST\": np.array([1e-4, 3e-4, 8e-4, 1.6e-3, 3.2e-3, 6.4e-3], dtype=float),\n",
        "    \"GQR_EARN_SCALE_LIST\": np.array([0.0, 0.01, 0.03, 0.05, 0.08, 0.12], dtype=float),\n",
        "    \"GQR_BUDGET0_LIST\": np.array([0.5, 1.0, 2.0, 4.0], dtype=float),\n",
        "    \"GQR_BUDGET_MIN_LIST\": np.array([-0.5, -2.0, -6.0], dtype=float),\n",
        "    \"GQR_BUDGET_MAX_LIST\": np.array([2.0, 4.0, 8.0], dtype=float),\n",
        "    \"JURIS_THRESHOLD_LIST\": np.array([0.2, 0.35, 0.45, 0.6], dtype=float),\n",
        "\n",
        "    # Landscape distribution parameters (broad, generic)\n",
        "    \"BARRIER_MU_LIST\": np.array([0.8, 1.0, 1.2, 1.5], dtype=float),\n",
        "    \"BARRIER_SIGMA_LIST\": np.array([0.10, 0.25, 0.40], dtype=float),\n",
        "    \"REORG_MU_LIST\": np.array([0.15, 0.35, 0.55], dtype=float),\n",
        "    \"REORG_SIGMA_LIST\": np.array([0.05, 0.10, 0.18], dtype=float),\n",
        "    \"DISS_MU_LIST\": np.array([0.6, 1.0, 1.4], dtype=float),\n",
        "    \"DISS_SIGMA_LIST\": np.array([0.15, 0.25, 0.45], dtype=float),\n",
        "\n",
        "    # Product specialness offsets (relative to sampled distributions)\n",
        "    \"PROD_BARRIER_OFFSET_LIST\": np.array([-0.5, -0.25, 0.0, 0.25], dtype=float),\n",
        "    \"PROD_DISS_OFFSET_LIST\": np.array([-0.5, -0.25, 0.0, 0.25], dtype=float),\n",
        "\n",
        "    # Warshel knobs (optional; included for robustness comparisons)\n",
        "    \"WARSHEL_LOWER_PRODUCT_LIST\": np.array([0.0, 0.1, 0.25, 0.4], dtype=float),\n",
        "    \"WARSHEL_RAISE_WASTE_LIST\": np.array([0.0, 0.03, 0.05, 0.1], dtype=float),\n",
        "    \"WARSHEL_DISS_REDUCE_LIST\": np.array([0.0, 0.03, 0.05, 0.1], dtype=float),\n",
        "}\n",
        "\n",
        "# ============================================================\n",
        "# RUN SETTINGS (edit these)\n",
        "# ============================================================\n",
        "\n",
        "OUTFILE = \"enz_governance_sweep_npz_only.npz\"\n",
        "\n",
        "N_SAMPLES = 400                 # number of parameter sets to sample (increase later)\n",
        "LANDSCAPES_PER_SAMPLE = 12       # replicate landscapes per parameter set\n",
        "SEEDS_PER_LANDSCAPE = 2          # replicate seeds per landscape\n",
        "SEED0 = 123\n",
        "\n",
        "# Chunked simulation settings (fast)\n",
        "EVENTS = 80_000\n",
        "CHUNK = 1_000\n",
        "N_CHUNKS = EVENTS // CHUNK\n",
        "PRODUCT_IDX = 0\n",
        "\n",
        "# Budget bookkeeping overhead constants (these match the style in your earlier code)\n",
        "GQR_BASE_OVERHEAD = 0.0003       # per event\n",
        "FILTER_DEAD_THRESH = 0.05        # effective filter below this => gqr_dead=1\n",
        "\n",
        "# For numerical stability / clipping\n",
        "BARRIER_CLIP = (0.05, 4.0)\n",
        "REORG_CLIP = (0.0, 2.0)\n",
        "DISS_CLIP = (0.0, 4.0)\n",
        "\n",
        "# ============================================================\n",
        "# Utility: sampling\n",
        "# ============================================================\n",
        "\n",
        "rng_master = np.random.default_rng(SEED0)\n",
        "\n",
        "def pick(rng, arr):\n",
        "    return arr[int(rng.integers(0, len(arr)))]\n",
        "\n",
        "def sample_param_set(rng):\n",
        "    return {\n",
        "        \"N_PATHS\": int(pick(rng, RANGES[\"N_PATHS_LIST\"])),\n",
        "        \"BETA\": float(pick(rng, RANGES[\"BETA_LIST\"])),\n",
        "        \"DISORDER_JUMP\": float(pick(rng, RANGES[\"DISORDER_JUMP_LIST\"])),\n",
        "        \"SHOCK_MODE\": int(pick(rng, RANGES[\"SHOCK_MODE_LIST\"])),\n",
        "\n",
        "        \"GQR_FILTER_BASE\": float(pick(rng, RANGES[\"GQR_FILTER_BASE_LIST\"])),\n",
        "        \"GQR_FILTER_COST\": float(pick(rng, RANGES[\"GQR_FILTER_COST_LIST\"])),\n",
        "        \"GQR_EARN_SCALE\": float(pick(rng, RANGES[\"GQR_EARN_SCALE_LIST\"])),\n",
        "        \"GQR_BUDGET0\": float(pick(rng, RANGES[\"GQR_BUDGET0_LIST\"])),\n",
        "        \"GQR_BUDGET_MIN\": float(pick(rng, RANGES[\"GQR_BUDGET_MIN_LIST\"])),\n",
        "        \"GQR_BUDGET_MAX\": float(pick(rng, RANGES[\"GQR_BUDGET_MAX_LIST\"])),\n",
        "        \"JURIS_THRESHOLD\": float(pick(rng, RANGES[\"JURIS_THRESHOLD_LIST\"])),\n",
        "\n",
        "        \"BARRIER_MU\": float(pick(rng, RANGES[\"BARRIER_MU_LIST\"])),\n",
        "        \"BARRIER_SIGMA\": float(pick(rng, RANGES[\"BARRIER_SIGMA_LIST\"])),\n",
        "        \"REORG_MU\": float(pick(rng, RANGES[\"REORG_MU_LIST\"])),\n",
        "        \"REORG_SIGMA\": float(pick(rng, RANGES[\"REORG_SIGMA_LIST\"])),\n",
        "        \"DISS_MU\": float(pick(rng, RANGES[\"DISS_MU_LIST\"])),\n",
        "        \"DISS_SIGMA\": float(pick(rng, RANGES[\"DISS_SIGMA_LIST\"])),\n",
        "\n",
        "        \"PROD_BARRIER_OFFSET\": float(pick(rng, RANGES[\"PROD_BARRIER_OFFSET_LIST\"])),\n",
        "        \"PROD_DISS_OFFSET\": float(pick(rng, RANGES[\"PROD_DISS_OFFSET_LIST\"])),\n",
        "\n",
        "        \"WARSHEL_LOWER_PRODUCT\": float(pick(rng, RANGES[\"WARSHEL_LOWER_PRODUCT_LIST\"])),\n",
        "        \"WARSHEL_RAISE_WASTE\": float(pick(rng, RANGES[\"WARSHEL_RAISE_WASTE_LIST\"])),\n",
        "        \"WARSHEL_DISS_REDUCE\": float(pick(rng, RANGES[\"WARSHEL_DISS_REDUCE_LIST\"])),\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# Landscape draw\n",
        "# ============================================================\n",
        "\n",
        "def draw_landscape(rng, N_PATHS, mu_b, sig_b, mu_r, sig_r, mu_d, sig_d, prod_bar_off, prod_diss_off):\n",
        "    barriers = np.clip(rng.normal(mu_b, sig_b, size=N_PATHS), *BARRIER_CLIP)\n",
        "    reorg = np.clip(rng.normal(mu_r, sig_r, size=N_PATHS), *REORG_CLIP)\n",
        "    diss = np.clip(rng.normal(mu_d, sig_d, size=N_PATHS), *DISS_CLIP)\n",
        "\n",
        "    # make product path slightly special relative to sampled distribution\n",
        "    barriers[PRODUCT_IDX] = np.clip(barriers[PRODUCT_IDX] + prod_bar_off, *BARRIER_CLIP)\n",
        "    reorg[PRODUCT_IDX] = np.clip(reorg[PRODUCT_IDX], *REORG_CLIP)\n",
        "    diss[PRODUCT_IDX] = np.clip(diss[PRODUCT_IDX] + prod_diss_off, *DISS_CLIP)\n",
        "\n",
        "    return barriers, reorg, diss\n",
        "\n",
        "# ============================================================\n",
        "# Weights\n",
        "# ============================================================\n",
        "\n",
        "def softmax_stable(x):\n",
        "    x = x - np.max(x)\n",
        "    w = np.exp(x)\n",
        "    s = w.sum()\n",
        "    return w / s if s > 0 else np.ones_like(w) / len(w)\n",
        "\n",
        "def weights_arrhenius(barriers, BETA):\n",
        "    return softmax_stable(-BETA * barriers)\n",
        "\n",
        "def weights_marcus(barriers, reorg, BETA):\n",
        "    return softmax_stable(-BETA * (barriers + reorg))\n",
        "\n",
        "def weights_warshel(barriers, BETA, lower_product, raise_waste):\n",
        "    b = barriers.copy()\n",
        "    b[PRODUCT_IDX] = max(0.0, b[PRODUCT_IDX] - lower_product)\n",
        "    if b.size > 1:\n",
        "        b[1:] = b[1:] + raise_waste\n",
        "    return softmax_stable(-BETA * b)\n",
        "\n",
        "def gqr_effective_filter(filter_setting, disorder, budget, BUDGET_MIN):\n",
        "    eff = filter_setting * max(0.0, 1.0 - disorder)\n",
        "    if budget < 0:\n",
        "        frac = max(0.0, (budget - BUDGET_MIN) / (0.0 - BUDGET_MIN))\n",
        "        eff *= frac\n",
        "    return float(np.clip(eff, 0.0, 1.0))\n",
        "\n",
        "def weights_gqr(barriers, BETA, filter_eff):\n",
        "    w = np.exp(-BETA * barriers)\n",
        "    if w.size > 1:\n",
        "        w[1:] *= (1.0 - filter_eff)\n",
        "    s = w.sum()\n",
        "    return (w / s) if s > 0 else np.ones_like(w) / len(w)\n",
        "\n",
        "# ============================================================\n",
        "# One run (chunked) for 4 regimes: Arr, Marcus, Warshel, GQR\n",
        "# ============================================================\n",
        "\n",
        "def run_once_chunked(params, barriers, reorg, diss, seed):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    N_PATHS = int(params[\"N_PATHS\"])\n",
        "    BETA = float(params[\"BETA\"])\n",
        "    dj = float(params[\"DISORDER_JUMP\"])\n",
        "    shock_mode = int(params[\"SHOCK_MODE\"])\n",
        "\n",
        "    # shock schedule in chunks\n",
        "    shock1 = int(0.25 * N_CHUNKS)\n",
        "    shock2 = int(0.60 * N_CHUNKS)\n",
        "\n",
        "    w_arr = weights_arrhenius(barriers, BETA)\n",
        "    w_mar = weights_marcus(barriers, reorg, BETA)\n",
        "\n",
        "    w_war = weights_warshel(\n",
        "        barriers,\n",
        "        BETA,\n",
        "        float(params[\"WARSHEL_LOWER_PRODUCT\"]),\n",
        "        float(params[\"WARSHEL_RAISE_WASTE\"]),\n",
        "    )\n",
        "\n",
        "    diss_warshel = np.maximum(0.0, diss - float(params[\"WARSHEL_DISS_REDUCE\"]))\n",
        "\n",
        "    # GQR\n",
        "    budget = float(params[\"GQR_BUDGET0\"])\n",
        "    BUDGET_MIN = float(params[\"GQR_BUDGET_MIN\"])\n",
        "    BUDGET_MAX = float(params[\"GQR_BUDGET_MAX\"])\n",
        "    filter_base = float(params[\"GQR_FILTER_BASE\"])\n",
        "    filter_cost = float(params[\"GQR_FILTER_COST\"])\n",
        "    earn_scale = float(params[\"GQR_EARN_SCALE\"])\n",
        "    juris_thr = float(params[\"JURIS_THRESHOLD\"])\n",
        "\n",
        "    # tallies\n",
        "    prod = np.zeros(4, dtype=float)\n",
        "    waste = np.zeros(4, dtype=float)\n",
        "    diss_tot = np.zeros(4, dtype=float)\n",
        "\n",
        "    disorder = 0.0\n",
        "    d_prod = float(diss[PRODUCT_IDX])\n",
        "\n",
        "    for c in range(N_CHUNKS):\n",
        "        if shock_mode == 1 and c == shock1:\n",
        "            disorder = float(np.clip(disorder + dj, 0.0, 0.95))\n",
        "        elif shock_mode == 2:\n",
        "            if c == shock1 or c == shock2:\n",
        "                disorder = float(np.clip(disorder + dj, 0.0, 0.95))\n",
        "\n",
        "        # Arrhenius\n",
        "        counts = rng.multinomial(CHUNK, w_arr)\n",
        "        prod[0] += counts[PRODUCT_IDX]\n",
        "        waste[0] += (CHUNK - counts[PRODUCT_IDX])\n",
        "        diss_tot[0] += float((counts * diss).sum())\n",
        "\n",
        "        # Marcus\n",
        "        counts = rng.multinomial(CHUNK, w_mar)\n",
        "        prod[1] += counts[PRODUCT_IDX]\n",
        "        waste[1] += (CHUNK - counts[PRODUCT_IDX])\n",
        "        diss_tot[1] += float((counts * diss).sum())\n",
        "\n",
        "        # Warshel\n",
        "        counts = rng.multinomial(CHUNK, w_war)\n",
        "        prod[2] += counts[PRODUCT_IDX]\n",
        "        waste[2] += (CHUNK - counts[PRODUCT_IDX])\n",
        "        diss_tot[2] += float((counts * diss_warshel).sum())\n",
        "\n",
        "        # GQR (dynamic)\n",
        "        filter_setting = filter_base if disorder <= juris_thr else 0.65 * filter_base\n",
        "        filter_eff = gqr_effective_filter(filter_setting, disorder, budget, BUDGET_MIN)\n",
        "        w_gqr = weights_gqr(barriers, BETA, filter_eff)\n",
        "\n",
        "        counts = rng.multinomial(CHUNK, w_gqr)\n",
        "        got_prod = float(counts[PRODUCT_IDX])\n",
        "        prod[3] += got_prod\n",
        "        waste[3] += (CHUNK - counts[PRODUCT_IDX])\n",
        "        diss_chunk = float((counts * diss).sum())\n",
        "        diss_tot[3] += diss_chunk\n",
        "\n",
        "        # Budget update (coarse but consistent with your earlier code style)\n",
        "        spend = CHUNK * ((filter_cost * filter_eff) + GQR_BASE_OVERHEAD)\n",
        "        earn = earn_scale * got_prod * max(0.0, 1.2 - d_prod)\n",
        "        budget = float(np.clip(budget + earn - spend, BUDGET_MIN, BUDGET_MAX))\n",
        "\n",
        "    y = prod / np.maximum(1.0, prod + waste)\n",
        "    dpp = diss_tot / np.maximum(1.0, prod)\n",
        "\n",
        "    final_filter = gqr_effective_filter(filter_base, disorder, budget, BUDGET_MIN)\n",
        "    gqr_dead = 1 if final_filter < FILTER_DEAD_THRESH else 0\n",
        "\n",
        "    return {\n",
        "        \"y_arr\": float(y[0]), \"y_mar\": float(y[1]), \"y_war\": float(y[2]), \"y_gqr\": float(y[3]),\n",
        "        \"dpp_arr\": float(dpp[0]), \"dpp_mar\": float(dpp[1]), \"dpp_war\": float(dpp[2]), \"dpp_gqr\": float(dpp[3]),\n",
        "        \"gqr_budget\": float(budget),\n",
        "        \"gqr_final_filter\": float(final_filter),\n",
        "        \"gqr_dead\": int(gqr_dead),\n",
        "        \"final_disorder\": float(disorder),\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# SWEEP RUNNER (NPZ ONLY)\n",
        "# ============================================================\n",
        "\n",
        "samples = [sample_param_set(rng_master) for _ in range(N_SAMPLES)]\n",
        "\n",
        "columns = [\n",
        "    # sample_id + replication ids\n",
        "    \"sample_id\", \"landscape_id\", \"seed_id\",\n",
        "\n",
        "    # key params\n",
        "    \"N_PATHS\", \"BETA\", \"DISORDER_JUMP\", \"SHOCK_MODE\",\n",
        "    \"GQR_FILTER_BASE\", \"GQR_FILTER_COST\", \"GQR_EARN_SCALE\",\n",
        "    \"GQR_BUDGET0\", \"GQR_BUDGET_MIN\", \"GQR_BUDGET_MAX\", \"JURIS_THRESHOLD\",\n",
        "    \"BARRIER_MU\", \"BARRIER_SIGMA\", \"REORG_MU\", \"REORG_SIGMA\", \"DISS_MU\", \"DISS_SIGMA\",\n",
        "    \"PROD_BARRIER_OFFSET\", \"PROD_DISS_OFFSET\",\n",
        "    \"WARSHEL_LOWER_PRODUCT\", \"WARSHEL_RAISE_WASTE\", \"WARSHEL_DISS_REDUCE\",\n",
        "\n",
        "    # outputs\n",
        "    \"y_arr\", \"y_mar\", \"y_war\", \"y_gqr\",\n",
        "    \"dpp_arr\", \"dpp_mar\", \"dpp_war\", \"dpp_gqr\",\n",
        "    \"gqr_budget\", \"gqr_final_filter\", \"gqr_dead\", \"final_disorder\",\n",
        "]\n",
        "\n",
        "rows = []\n",
        "t0 = time.time()\n",
        "last_beat = t0\n",
        "\n",
        "total_runs = N_SAMPLES * LANDSCAPES_PER_SAMPLE * SEEDS_PER_LANDSCAPE\n",
        "run_count = 0\n",
        "\n",
        "for si, p in enumerate(samples):\n",
        "    for li in range(LANDSCAPES_PER_SAMPLE):\n",
        "        # draw a new landscape per replicate\n",
        "        seed_land = int(rng_master.integers(1, 2**31 - 1))\n",
        "        rng_land = np.random.default_rng(seed_land)\n",
        "\n",
        "        barriers, reorg, diss = draw_landscape(\n",
        "            rng_land,\n",
        "            p[\"N_PATHS\"],\n",
        "            p[\"BARRIER_MU\"], p[\"BARRIER_SIGMA\"],\n",
        "            p[\"REORG_MU\"], p[\"REORG_SIGMA\"],\n",
        "            p[\"DISS_MU\"], p[\"DISS_SIGMA\"],\n",
        "            p[\"PROD_BARRIER_OFFSET\"], p[\"PROD_DISS_OFFSET\"],\n",
        "        )\n",
        "\n",
        "        for sj in range(SEEDS_PER_LANDSCAPE):\n",
        "            seed_run = int(rng_master.integers(1, 2**31 - 1))\n",
        "            out = run_once_chunked(p, barriers, reorg, diss, seed_run)\n",
        "\n",
        "            row = [\n",
        "                si, li, sj,\n",
        "                p[\"N_PATHS\"], p[\"BETA\"], p[\"DISORDER_JUMP\"], p[\"SHOCK_MODE\"],\n",
        "                p[\"GQR_FILTER_BASE\"], p[\"GQR_FILTER_COST\"], p[\"GQR_EARN_SCALE\"],\n",
        "                p[\"GQR_BUDGET0\"], p[\"GQR_BUDGET_MIN\"], p[\"GQR_BUDGET_MAX\"], p[\"JURIS_THRESHOLD\"],\n",
        "                p[\"BARRIER_MU\"], p[\"BARRIER_SIGMA\"], p[\"REORG_MU\"], p[\"REORG_SIGMA\"], p[\"DISS_MU\"], p[\"DISS_SIGMA\"],\n",
        "                p[\"PROD_BARRIER_OFFSET\"], p[\"PROD_DISS_OFFSET\"],\n",
        "                p[\"WARSHEL_LOWER_PRODUCT\"], p[\"WARSHEL_RAISE_WASTE\"], p[\"WARSHEL_DISS_REDUCE\"],\n",
        "                out[\"y_arr\"], out[\"y_mar\"], out[\"y_war\"], out[\"y_gqr\"],\n",
        "                out[\"dpp_arr\"], out[\"dpp_mar\"], out[\"dpp_war\"], out[\"dpp_gqr\"],\n",
        "                out[\"gqr_budget\"], out[\"gqr_final_filter\"], out[\"gqr_dead\"], out[\"final_disorder\"],\n",
        "            ]\n",
        "            rows.append(row)\n",
        "\n",
        "            run_count += 1\n",
        "            now = time.time()\n",
        "            if now - last_beat > 10:\n",
        "                elapsed = now - t0\n",
        "                print(f\"progress: {run_count}/{total_runs} ({run_count/total_runs:5.1%}) elapsed={elapsed:6.1f}s\")\n",
        "                last_beat = now\n",
        "\n",
        "rows = np.array(rows, dtype=float)\n",
        "\n",
        "# Save everything needed for later plotting/analysis\n",
        "np.savez(\n",
        "    OUTFILE,\n",
        "    rows=rows,\n",
        "    columns=np.array(columns),\n",
        "\n",
        "    # store the sampled parameter sets as a structured array for later grouping\n",
        "    samples=np.array(samples, dtype=object),\n",
        "\n",
        "    # store sweep ranges and meta\n",
        "    ranges=np.array([RANGES], dtype=object),\n",
        "    meta=np.array([{\n",
        "        \"EVENTS\": EVENTS,\n",
        "        \"CHUNK\": CHUNK,\n",
        "        \"N_CHUNKS\": N_CHUNKS,\n",
        "        \"N_SAMPLES\": N_SAMPLES,\n",
        "        \"LANDSCAPES_PER_SAMPLE\": LANDSCAPES_PER_SAMPLE,\n",
        "        \"SEEDS_PER_LANDSCAPE\": SEEDS_PER_LANDSCAPE,\n",
        "        \"SEED0\": SEED0,\n",
        "        \"timestamp\": time.time(),\n",
        "    }], dtype=object),\n",
        ")\n",
        "\n",
        "print(\"Saved NPZ:\", OUTFILE)\n",
        "print(\"rows shape:\", rows.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMErKgBOrQUtKU2fkDE9b3G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}