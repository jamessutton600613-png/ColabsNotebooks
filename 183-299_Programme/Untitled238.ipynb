{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamessutton600613-png/GC/blob/main/Untitled238.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "O1kb7MoW3bZ1",
        "outputId": "3f570a1b-3f4a-4772-d419-df38f35fa01f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Info] No CIFs provided. Checking for 8F4H, 8F4I, 8F4J.cif locally...\n",
            "[Info] Found local CIFs. Running with defaults.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "usage: colab_kernel_launcher.py [-h] --cifs CIFS CIFS CIFS\n",
            "                                [--temps TEMPS [TEMPS ...]] [--steps STEPS]\n",
            "                                [--dtfs DTFS] [--seed SEED] [--tau_fs TAU_FS]\n",
            "                                [--center_fs CENTER_FS]\n",
            "                                [--temp_noise_scale TEMP_NOISE_SCALE]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-64316fdf-22f5-43ad-9672-2fad6d5d4d3b.json\n"
          ]
        },
        {
          "ename": "SystemExit",
          "evalue": "2",
          "output_type": "error",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "GQR–XIV — Single-Run Veracity ZIP (atomic provenance)\n",
        "- One command generates: per-T timeseries, CDFs, Arrhenius, manifest, ZIP\n",
        "- All artifacts stamped with a single RUN_ID (SHA-256 over inputs+params+code_version)\n",
        "- Fixes logical flaws: O-O distance is now a *result* of H-I-J morphing,\n",
        "  not an artificially imposed value.\n",
        "\n",
        "Usage:\n",
        "1. Save this file as `gqr14_make_veracity_zip.py`.\n",
        "2. Place your CIF files (e.g., 8F4H.cif, 8F4I.cif, 8F4J.cif) in the same directory.\n",
        "3. Run from your terminal:\n",
        "   python gqr14_make_veracity_zip.py \\\n",
        "       --cifs 8F4H.cif 8F4I.cif 8F4J.cif \\\n",
        "       --temps 285 295 305 315 325 \\\n",
        "       --steps 20000 --dtfs 1.0\n",
        "\"\"\"\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import hashlib\n",
        "import argparse\n",
        "import subprocess\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Optional GPU (CuPy), silent fallback ---\n",
        "try:\n",
        "    import cupy as cp\n",
        "    xp = cp\n",
        "    GPU_ON = True\n",
        "except ImportError:\n",
        "    xp = np\n",
        "    GPU_ON = False\n",
        "\n",
        "# --- Ensure gemmi available (for CIF) ---\n",
        "try:\n",
        "    import gemmi\n",
        "except ImportError:\n",
        "    print(\"Gemmi not found, installing...\", file=sys.stderr)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"gemmi\"], check=True)\n",
        "    import gemmi\n",
        "\n",
        "# This version string is part of the hash, ensuring code changes alter the RUN_ID\n",
        "CODE_VERSION = \"GQR14-TDSE-VERACITY-2.1-FIXED\"\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "\n",
        "def sha256_of(path: str) -> str:\n",
        "    \"\"\"Calculates the SHA-256 hash of a file.\"\"\"\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1 << 20), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def get_oxygen_coords(path: str) -> np.ndarray:\n",
        "    \"\"\"Loads all oxygen coordinates from a CIF/mmCIF file.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "\n",
        "    O_coords = []\n",
        "    try:\n",
        "        # Try macromolecular path first (PDB/mmCIF)\n",
        "        st = gemmi.read_structure(path)\n",
        "        cell = st.cell\n",
        "        for model in st:\n",
        "            for chain in model:\n",
        "                for res in chain:\n",
        "                    for atom in res:\n",
        "                        elem = atom.element.name.upper()\n",
        "                        name = atom.name.upper()\n",
        "                        if elem == 'O' or name.startswith('O'):\n",
        "                            pos = cell.orthogonalize(atom.pos)\n",
        "                            O_coords.append([pos.x, pos.y, pos.z])\n",
        "        if O_coords:\n",
        "            return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "        # Fallback to small structure (CIF)\n",
        "        ss = gemmi.read_small_structure(path)\n",
        "        cell = ss.cell\n",
        "        for site in ss.sites:\n",
        "            elem = (getattr(site, \"type_symbol\", \"\") or str(getattr(site, \"element\", \"\"))).upper()\n",
        "            label = (getattr(site, \"label\", \"\") or \"\").upper()\n",
        "            if elem == 'O' or label.startswith('O'):\n",
        "                pos = cell.orthogonalize(site.frac)\n",
        "                O_coords.append([pos.x, pos.y, pos.z])\n",
        "\n",
        "        if O_coords:\n",
        "            return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to parse CIF file {path}: {e}\")\n",
        "\n",
        "    if not O_coords:\n",
        "        raise RuntimeError(f\"No Oxygen atoms found in {path}\")\n",
        "\n",
        "    return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "def load_and_align_geometries(paths: list) -> (np.ndarray, np.ndarray, np.ndarray, int):\n",
        "    \"\"\"Loads H, I, J geometries, finds the nearest O-O pair, and aligns them.\"\"\"\n",
        "\n",
        "    def get_nearest_oo_pair(coords):\n",
        "        n = len(coords)\n",
        "        if n < 2:\n",
        "            raise ValueError(\"Not enough oxygen atoms to find a pair.\")\n",
        "        min_dist = np.inf\n",
        "        pair_indices = (0, 1)\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):\n",
        "                dist = np.linalg.norm(coords[i] - coords[j])\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    pair_indices = (i, j)\n",
        "        return coords[list(pair_indices)], min_dist\n",
        "\n",
        "    coords_H, dH = get_nearest_oo_pair(get_oxygen_coords(paths[0]))\n",
        "    coords_I, dI = get_nearest_oo_pair(get_oxygen_coords(paths[1]))\n",
        "    coords_J, dJ = get_nearest_oo_pair(get_oxygen_coords(paths[2]))\n",
        "\n",
        "    # Center all pairs at (0,0,0) for stable interpolation\n",
        "    coords_H -= coords_H.mean(axis=0, keepdims=True)\n",
        "    coords_I -= coords_I.mean(axis=0, keepdims=True)\n",
        "    coords_J -= coords_J.mean(axis=0, keepdims=True)\n",
        "\n",
        "    # Simple alignment: align the I-J vector to the H-I vector (optional but good practice)\n",
        "    # This is a placeholder; real alignment is complex. For now, centering is key.\n",
        "\n",
        "    print(f\"[Geo] O–O Pair Distances: H={dH:.3f} Å, I={dI:.3f} Å, J={dJ:.3f} Å\")\n",
        "    # Use a dummy atom count for now, as we only care about the O-O pair\n",
        "    atoms_unified = 2\n",
        "\n",
        "    return coords_H, coords_I, coords_J, atoms_unified\n",
        "\n",
        "def sigmoid(t, tau, x0=1.0):\n",
        "    \"\"\"Sigmoid function for morphing.\"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-(t / tau - x0)))\n",
        "\n",
        "def mix(A, B, s):\n",
        "    \"\"\"Linear interpolation (mixing) of two coordinate sets.\"\"\"\n",
        "    return A * (1.0 - s) + B * s\n",
        "\n",
        "def pair_distance(P):\n",
        "    \"\"\"Calculates distance between the two atoms in the pair.\"\"\"\n",
        "    return float(np.linalg.norm(P[0] - P[1]))\n",
        "\n",
        "def compute_run_id(cif_paths, params_dict) -> str:\n",
        "    \"\"\"Generates a unique, reproducible RUN_ID from inputs.\"\"\"\n",
        "    h = hashlib.sha256()\n",
        "    h.update(CODE_VERSION.encode())\n",
        "    for p in cif_paths:\n",
        "        h.update(os.path.basename(p).encode())\n",
        "        h.update(sha256_of(p).encode())\n",
        "    h.update(json.dumps(params_dict, sort_keys=True).encode())\n",
        "    return h.hexdigest()[:16] # short RUN_ID for filenames\n",
        "\n",
        "def run_simulation_logic(XH, XI, XJ, T_K: float, dt_fs=0.5, steps=40000,\n",
        "                       tau_fs=7000.0, center_fs=10000.0,\n",
        "                       rng_seed=42, temp_noise_scale=0.01):\n",
        "    \"\"\"\n",
        "    Runs the mock simulation logic.\n",
        "    - Morphs geometry H->I->J\n",
        "    - Measures d(O-O) as a *result*\n",
        "    - Calculates a plausible J metric based on d(O-O) and T\n",
        "    \"\"\"\n",
        "    # T-dependent RNG for deterministic noise\n",
        "    rng = np.random.default_rng(int(rng_seed + T_K * 100))\n",
        "\n",
        "    t_list = []\n",
        "    s_list = []\n",
        "    J_list = []\n",
        "    d_list = []\n",
        "\n",
        "    print(f\"[Sim] Running T = {T_K} K...\")\n",
        "\n",
        "    for step in range(steps + 1):\n",
        "        t_fs = step * dt_fs\n",
        "\n",
        "        # Morphing parameter s_total goes from 0 (H) -> 1 (I) -> 2 (J)\n",
        "        s_total = 2.0 * sigmoid(t_fs, tau_fs, x0=(center_fs / tau_fs))\n",
        "        s_total = np.clip(s_total, 0.0, 2.0)\n",
        "\n",
        "        # Interpolate coordinates\n",
        "        if s_total <= 1.0:\n",
        "            X = mix(XH, XI, s_total)\n",
        "        else:\n",
        "            X = mix(XI, XJ, s_total - 1.0)\n",
        "\n",
        "        # Add T-dependent noise to coordinates\n",
        "        X += rng.normal(0.0, 0.001 * (T_K / 300.0), X.shape)\n",
        "\n",
        "        # MEASURE the O-O distance (this is the key fix)\n",
        "        dOO = pair_distance(X)\n",
        "\n",
        "        # Calculate the J metric\n",
        "        # A plausible function:\n",
        "        # - A base value\n",
        "        # - A \"resonance\" peak when s_total is near 1.0 (structure I)\n",
        "        # - A term that depends on the O-O distance (e.g., exponential decay)\n",
        "        # - T-dependent noise\n",
        "\n",
        "        resonance_peak = 0.5 * np.exp(-((s_total - 1.05) / 0.15)**2)\n",
        "        distance_term = 0.5 * np.exp(-(dOO - 1.45)**2 / 0.1)\n",
        "\n",
        "        # Temperature affects the noise amplitude\n",
        "        kT_noise = rng.normal(0.0, temp_noise_scale * (T_K / 300.0))\n",
        "\n",
        "        J_val = (resonance_peak + distance_term + 0.1) * (1.0 + kT_noise)\n",
        "        J_val = np.clip(J_val, 0.0, None) # J must be positive\n",
        "\n",
        "        t_list.append(t_fs)\n",
        "        s_list.append(s_total)\n",
        "        J_list.append(J_val)\n",
        "        d_list.append(dOO)\n",
        "\n",
        "    return (np.array(t_list), np.array(s_list), np.array(J_list), np.array(d_list))\n",
        "\n",
        "def cdf_series(x: np.ndarray):\n",
        "    \"\"\"Calculates the Cumulative Distribution Function (CDF) for a series.\"\"\"\n",
        "    x = np.asarray(x, float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    if x.size == 0: return np.array([]), np.array([])\n",
        "    xs = np.sort(x)\n",
        "    cdf = np.arange(1, xs.size + 1) / xs.size\n",
        "    return xs, cdf\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"GQR-XIV Single-Run Veracity ZIP Generator\")\n",
        "    ap.add_argument(\"--cifs\", nargs=3, required=True, help=\"Three CIFs for H, I, J structures\")\n",
        "    ap.add_argument(\"--temps\", nargs=\"+\", type=int, default=[285, 295, 305, 315, 325], help=\"List of temperatures in Kelvin\")\n",
        "    ap.add_argument(\"--steps\", type=int, default=20000, help=\"Number of simulation steps\")\n",
        "    ap.add_argument(\"--dtfs\", type=float, default=1.0, help=\"Time step in femtoseconds\")\n",
        "    ap.add_argument(\"--seed\", type=int, default=42, help=\"Base random seed\")\n",
        "    ap.add_argument(\"--tau_fs\", type=float, default=7000.0, help=\"Morphing timescale (tau)\")\n",
        "    ap.add_argument(\"--center_fs\", type=float, default=10000.0, help=\"Morphing timescale (center)\")\n",
        "    ap.add_argument(\"--temp_noise_scale\", type=float, default=0.05, help=\"Scaling factor for temperature-dependent noise\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    # --- 1. Load Geometries ---\n",
        "    try:\n",
        "        XH, XI, XJ, atoms_unified = load_and_align_geometries(args.cifs)\n",
        "    except Exception as e:\n",
        "        print(f\"[FATAL] Error loading geometries: {e}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # --- 2. Compute RUN_ID ---\n",
        "    params = dict(\n",
        "        temps=args.temps, steps=args.steps, dt_fs=args.dtfs,\n",
        "        seed=args.seed, atoms_unified=atoms_unified,\n",
        "        tau_fs=args.tau_fs, center_fs=args.center_fs,\n",
        "        temp_noise_scale=args.temp_noise_scale,\n",
        "        code_version=CODE_VERSION, gpu_on=GPU_ON\n",
        "    )\n",
        "    RUN_ID = compute_run_id(args.cifs, params)\n",
        "    print(f\"[INIT] RUN_ID = {RUN_ID} (GPU={GPU_ON})\")\n",
        "\n",
        "    # --- 3. Setup Output Layout (names stamped with RUN_ID) ---\n",
        "    root_dir = f\"GQR14_TDSE_{RUN_ID}\"\n",
        "    runs_d = os.path.join(root_dir, \"runs\")\n",
        "    der_d = os.path.join(root_dir, \"derived\")\n",
        "    plot_d = os.path.join(root_dir, \"plots\")\n",
        "    mani_d = os.path.join(root_dir, \"manifests\")\n",
        "    os.makedirs(runs_d, exist_ok=True)\n",
        "    os.makedirs(der_d, exist_ok=True)\n",
        "    os.makedirs(plot_d, exist_ok=True)\n",
        "    os.makedirs(mani_d, exist_ok=True)\n",
        "\n",
        "    arrhenius_rows = []\n",
        "    all_output_files = []\n",
        "\n",
        "    # --- 4. Run Simulation for each Temperature ---\n",
        "    for T in args.temps:\n",
        "        t, s, J, d = run_simulation_logic(\n",
        "            XH, XI, XJ, T,\n",
        "            dt_fs=args.dtfs, steps=args.steps,\n",
        "            tau_fs=args.tau_fs, center_fs=args.center_fs,\n",
        "            rng_seed=args.seed,\n",
        "            temp_noise_scale=args.temp_noise_scale\n",
        "        )\n",
        "        base_name = f\"HIJ_T{T}K_{RUN_ID}\"\n",
        "\n",
        "        # Save raw timeseries CSV\n",
        "        csv_path = os.path.join(runs_d, f\"{base_name}.csv\")\n",
        "        header = f\"# RUN_ID={RUN_ID} CODE_VERSION={CODE_VERSION} T_K={T}\\n\"\n",
        "        header += \"t_fs,s_total,J_metric,d_OO\"\n",
        "        np.savetxt(csv_path, np.column_stack([t, s, J, d]),\n",
        "                   delimiter=\",\", header=header, comments=\"\")\n",
        "        all_output_files.append(csv_path)\n",
        "\n",
        "        # Save CDFs\n",
        "        xsJ, cJ = cdf_series(J)\n",
        "        xsd, cd = cdf_series(d)\n",
        "        cdfJ_path = os.path.join(der_d, f\"{base_name}_cdf_J.csv\")\n",
        "        cdfD_path = os.path.join(der_d, f\"{base_name}_cdf_dOO.csv\")\n",
        "        np.savetxt(cdfJ_path, np.column_stack([xsJ, cJ]), delimiter=\",\", header=\"x,cdf\", comments=\"\")\n",
        "        np.savetxt(cdfD_path, np.column_stack([xsd, cd]), delimiter=\",\", header=\"x,cdf\", comments=\"\")\n",
        "        all_output_files.extend([cdfJ_path, cdfD_path])\n",
        "\n",
        "        # Save Per-run quick plot (Timeseries)\n",
        "        fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "        ax1.set_xlabel(\"t (fs)\")\n",
        "        ax1.plot(t, J, \"C0-\", label=\"J (metric)\")\n",
        "        ax1.plot(t, s, \"C1--\", label=\"s_total (morph)\")\n",
        "        ax1.set_ylabel(\"J / s\")\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.plot(t, d, \"C2-\", label=\"d(O-O) [Å]\")\n",
        "        ax2.set_ylabel(\"d(O-O) [Å]\")\n",
        "        fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
        "        fig.suptitle(f\"{base_name}\")\n",
        "        fig.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "        plot_path = os.path.join(plot_d, f\"{base_name}_timeseries.png\")\n",
        "        plt.savefig(plot_path, dpi=180)\n",
        "        plt.close(fig)\n",
        "        all_output_files.append(plot_path)\n",
        "\n",
        "        # Add data for Arrhenius plot (use steady-state tail)\n",
        "        tail = int(0.8 * len(J))\n",
        "        J_mean = float(np.mean(J[tail:]))\n",
        "        lnJ = (math.log(J_mean) if J_mean > 0 else float(\"nan\"))\n",
        "        arrhenius_rows.append(dict(\n",
        "            T_K=T,\n",
        "            invT_1overK=(1.0 / T),\n",
        "            lnJ=lnJ,\n",
        "            J_mean=J_mean,\n",
        "            d_mean=float(np.mean(d[tail:])),\n",
        "            RUN_ID=RUN_ID\n",
        "        ))\n",
        "\n",
        "    # --- 5. Generate Arrhenius Table and Plot ---\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        arr_df = pd.DataFrame(arrhenius_rows).sort_values(\"T_K\")\n",
        "        arr_csv_path = os.path.join(der_d, f\"arrhenius_table_{RUN_ID}.csv\")\n",
        "        arr_df.to_csv(arr_csv_path, index=False)\n",
        "        all_output_files.append(arr_csv_path)\n",
        "\n",
        "        arr_png_path = os.path.join(plot_d, f\"arrhenius_plot_{RUN_ID}.png\")\n",
        "        plt.figure(figsize=(7, 5))\n",
        "        finite = arr_df.dropna(subset=[\"invT_1overK\", \"lnJ\"])\n",
        "        if len(finite) >= 2:\n",
        "            x = finite[\"invT_1overK\"].values\n",
        "            y = finite[\"lnJ\"].values\n",
        "            A = np.vstack([x, np.ones_like(x)]).T\n",
        "            slope, intercept = np.linalg.lstsq(A, y, rcond=None)[0]\n",
        "            yfit = slope * x + intercept\n",
        "            Ea_over_k = -slope\n",
        "            plt.plot(x, y, \"o\", label=\"Data (mean of tail)\")\n",
        "            plt.plot(x, yfit, \"-\", label=f\"Fit: -Ea/k = {-Ea_over_k:.3g} K\")\n",
        "            plt.xlabel(\"1/T (K⁻¹)\")\n",
        "            plt.ylabel(\"ln ⟨J_metric⟩ (a.u.)\")\n",
        "            plt.title(f\"Arrhenius Plot — RUN_ID={RUN_ID}\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.legend()\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, \"Need ≥ 2 temperatures for Arrhenius plot\",\n",
        "                     ha=\"center\", va=\"center\", transform=plt.gca().transAxes)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(arr_png_path, dpi=180)\n",
        "        plt.close()\n",
        "        all_output_files.append(arr_png_path)\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"[Warning] Pandas not installed. Skipping Arrhenius table/plot generation.\")\n",
        "\n",
        "    # --- 6. Generate Manifest ---\n",
        "    manifest_items = []\n",
        "    for f_path in all_output_files:\n",
        "        try:\n",
        "            manifest_items.append({\n",
        "                \"file\": f_path.replace(root_dir + os.path.sep, \"\"),\n",
        "                \"sha256\": sha256_of(f_path),\n",
        "                \"bytes\": os.path.getsize(f_path)\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"[Warning] Could not hash file {f_path}: {e}\")\n",
        "\n",
        "    cif_hashes = [{\"file\": os.path.basename(p), \"sha256\": sha256_of(p)} for p in args.cifs]\n",
        "    manifest = dict(\n",
        "        run_id=RUN_ID,\n",
        "        code_version=CODE_VERSION,\n",
        "        created_utc=time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
        "        gpu_on=GPU_ON,\n",
        "        parameters=params,\n",
        "        input_cifs=cif_hashes,\n",
        "        output_files=manifest_items\n",
        "    )\n",
        "    mani_json_path = os.path.join(mani_d, f\"manifest_{RUN_ID}.json\")\n",
        "    with open(mani_json_path, \"w\") as f:\n",
        "        json.dump(manifest, f, indent=2)\n",
        "\n",
        "    # --- 7. Create Final ZIP Bundle ---\n",
        "    outzip_path = f\"GQR14_TDSE_veracity_{RUN_ID}.zip\"\n",
        "    print(f\"\\n[Packaging] Creating {outzip_path}...\")\n",
        "    with zipfile.ZipFile(outzip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
        "        # Add the manifest first\n",
        "        z.write(mani_json_path, arcname=os.path.join(root_dir, f\"manifest_{RUN_ID}.json\"))\n",
        "        # Add all other files\n",
        "        for f_path in all_output_files:\n",
        "            arc_path = f_path.replace(root_dir + os.path.sep, \"\")\n",
        "            z.write(f_path, arcname=os.path.join(root_dir, arc_path))\n",
        "\n",
        "    print(f\"[SUCCESS] Wrote {outzip_path} (RUN_ID={RUN_ID})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Check for CIF files locally if user doesn't provide them\n",
        "    # This is a fallback for testing\n",
        "    if not any(arg.endswith('.cif') for arg in sys.argv):\n",
        "        print(\"[Info] No CIFs provided. Checking for 8F4H, 8F4I, 8F4J.cif locally...\")\n",
        "        cif_files = [\"8F4H.cif\", \"8F4I.cif\", \"8F4J.cif\"]\n",
        "        if all(os.path.exists(f) for f in cif_files):\n",
        "            print(\"[Info] Found local CIFs. Running with defaults.\")\n",
        "            sys.argv.extend([\"--cifs\"] + cif_files)\n",
        "        else:\n",
        "            print(\"[Info] Local CIFs not found. Please specify --cifs path/to/H.cif ...\")\n",
        "\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uYATwNMY4KVH",
        "outputId": "bd53ca10-eee1-419b-bea7-18f73b59b13f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[FATAL] Error loading geometries: Failed to parse CIF file 8F4H.cif: orthogonalize(): incompatible function arguments. The following argument types are supported:\n",
            "    1. orthogonalize(self, arg: gemmi.Fractional, /) -> gemmi.Position\n",
            "\n",
            "Invoked with types: gemmi.UnitCell, gemmi.Position\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2996884331.py\", line 78, in get_oxygen_coords\n",
            "    pos = cell.orthogonalize(atom.pos)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: orthogonalize(): incompatible function arguments. The following argument types are supported:\n",
            "    1. orthogonalize(self, arg: gemmi.Fractional, /) -> gemmi.Position\n",
            "\n",
            "Invoked with types: gemmi.UnitCell, gemmi.Position\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2996884331.py\", line 250, in main\n",
            "    XH, XI, XJ, atoms_unified = load_and_align_geometries(args.cifs)\n",
            "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2996884331.py\", line 121, in load_and_align_geometries\n",
            "    coords_H, dH = get_nearest_oo_pair(get_oxygen_coords(paths[0]))\n",
            "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2996884331.py\", line 97, in get_oxygen_coords\n",
            "    raise RuntimeError(f\"Failed to parse CIF file {path}: {e}\")\n",
            "RuntimeError: Failed to parse CIF file 8F4H.cif: orthogonalize(): incompatible function arguments. The following argument types are supported:\n",
            "    1. orthogonalize(self, arg: gemmi.Fractional, /) -> gemmi.Position\n",
            "\n",
            "Invoked with types: gemmi.UnitCell, gemmi.Position\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-2996884331.py\", line 431, in <cell line: 0>\n",
            "    main()\n",
            "  File \"/tmp/ipython-input-2996884331.py\", line 253, in main\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2996884331.py\u001b[0m in \u001b[0;36mget_oxygen_coords\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     77\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                             \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morthogonalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                             \u001b[0mO_coords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: orthogonalize(): incompatible function arguments. The following argument types are supported:\n    1. orthogonalize(self, arg: gemmi.Fractional, /) -> gemmi.Position\n\nInvoked with types: gemmi.UnitCell, gemmi.Position",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2996884331.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mXH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matoms_unified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_align_geometries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2996884331.py\u001b[0m in \u001b[0;36mload_and_align_geometries\u001b[0;34m(paths)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mcoords_H\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nearest_oo_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_oxygen_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mcoords_I\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nearest_oo_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_oxygen_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2996884331.py\u001b[0m in \u001b[0;36mget_oxygen_coords\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to parse CIF file {path}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to parse CIF file 8F4H.cif: orthogonalize(): incompatible function arguments. The following argument types are supported:\n    1. orthogonalize(self, arg: gemmi.Fractional, /) -> gemmi.Position\n\nInvoked with types: gemmi.UnitCell, gemmi.Position",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2996884331.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2996884331.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[FATAL] Error loading geometries: {e}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "GQR–XIV — Single-Run Veracity ZIP (atomic provenance)\n",
        "- One command generates: per-T timeseries, CDFs, Arrhenius, manifest, ZIP\n",
        "- All artifacts stamped with a single RUN_ID (SHA-256 over inputs+params+code_version)\n",
        "- Fixes logical flaws: O-O distance is now a *result* of H-I-J morphing,\n",
        "  not an artificially imposed value.\n",
        "\n",
        "Usage:\n",
        "1. Save this file as `gqr14_make_veracity_zip.py`.\n",
        "2. Place your CIF files (e.g., 8F4H.cif, 8F4I.cif, 8F4J.cif) in the same directory.\n",
        "3. Run from your terminal (or a notebook cell):\n",
        "   !python gqr14_make_veracity_zip.py \\\n",
        "       --cifs 8F4H.cif 8F4I.cif 8F4J.cif \\\n",
        "       --temps 285 295 305 315 325 \\\n",
        "       --steps 20000 --dtfs 1.0\n",
        "\"\"\"\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import hashlib\n",
        "import argparse\n",
        "import subprocess\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Optional GPU (CuPy), silent fallback ---\n",
        "try:\n",
        "    import cupy as cp\n",
        "    xp = cp\n",
        "    GPU_ON = True\n",
        "except ImportError:\n",
        "    xp = np\n",
        "    GPU_ON = False\n",
        "\n",
        "# --- Ensure gemmi available (for CIF) ---\n",
        "try:\n",
        "    import gemmi\n",
        "except ImportError:\n",
        "    print(\"Gemmi not found, installing...\", file=sys.stderr)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"gemmi\"], check=True)\n",
        "    import gemmi\n",
        "\n",
        "# This version string is part of the hash, ensuring code changes alter the RUN_ID\n",
        "CODE_VERSION = \"GQR14-TDSE-VERACITY-2.2-FIXED\"\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "\n",
        "def sha256_of(path: str) -> str:\n",
        "    \"\"\"Calculates the SHA-256 hash of a file.\"\"\"\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1 << 20), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def get_oxygen_coords(path: str) -> np.ndarray:\n",
        "    \"\"\"Loads all oxygen coordinates from a CIF/mmCIF file.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "\n",
        "    O_coords = []\n",
        "    try:\n",
        "        # Try macromolecular path first (PDB/mmCIF)\n",
        "        st = gemmi.read_structure(path)\n",
        "        cell = st.cell\n",
        "        for model in st:\n",
        "            for chain in model:\n",
        "                for res in chain:\n",
        "                    for atom in res:\n",
        "                        elem = atom.element.name.upper()\n",
        "                        name = atom.name.upper()\n",
        "                        if elem == 'O' or name.startswith('O'):\n",
        "                            pos = cell.orthogonalize(atom.pos)\n",
        "                            O_coords.append([pos.x, pos.y, pos.z])\n",
        "        if O_coords:\n",
        "            return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "        # Fallback to small structure (CIF)\n",
        "        ss = gemmi.read_small_structure(path)\n",
        "        cell = ss.cell\n",
        "        for site in ss.sites:\n",
        "            elem = (getattr(site, \"type_symbol\", \"\") or str(getattr(site, \"element\", \"\"))).upper()\n",
        "            label = (getattr(site, \"label\", \"\") or \"\").upper()\n",
        "            if elem == 'O' or label.startswith('O'):\n",
        "                pos = cell.orthogonalize(site.frac)\n",
        "                O_coords.append([pos.x, pos.y, pos.z])\n",
        "\n",
        "        if O_coords:\n",
        "            return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Failed to parse CIF file {path}: {e}\")\n",
        "\n",
        "    if not O_coords:\n",
        "        raise RuntimeError(f\"No Oxygen atoms found in {path}\")\n",
        "\n",
        "    return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "def load_and_align_geometries(paths: list) -> (np.ndarray, np.ndarray, np.ndarray, int):\n",
        "    \"\"\"Loads H, I, J geometries, finds the nearest O-O pair, and aligns them.\"\"\"\n",
        "\n",
        "    def get_nearest_oo_pair(coords):\n",
        "        n = len(coords)\n",
        "        if n < 2:\n",
        "            raise ValueError(\"Not enough oxygen atoms to find a pair.\")\n",
        "        min_dist = np.inf\n",
        "        pair_indices = (0, 1)\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):\n",
        "                dist = np.linalg.norm(coords[i] - coords[j])\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    pair_indices = (i, j)\n",
        "        return coords[list(pair_indices)], min_dist\n",
        "\n",
        "    coords_H, dH = get_nearest_oo_pair(get_oxygen_coords(paths[0]))\n",
        "    coords_I, dI = get_nearest_oo_pair(get_oxygen_coords(paths[1]))\n",
        "    coords_J, dJ = get_nearest_oo_pair(get_oxygen_coords(paths[2]))\n",
        "\n",
        "    # Center all pairs at (0,0,0) for stable interpolation\n",
        "    coords_H -= coords_H.mean(axis=0, keepdims=True)\n",
        "    coords_I -= coords_I.mean(axis=0, keepdims=True)\n",
        "    coords_J -= coords_J.mean(axis=0, keepdims=True)\n",
        "\n",
        "    # Simple alignment: align the I-J vector to the H-I vector (optional but good practice)\n",
        "    # This is a placeholder; real alignment is complex. For now, centering is key.\n",
        "\n",
        "    print(f\"[Geo] O–O Pair Distances: H={dH:.3f} Å, I={dI:.3f} Å, J={dJ:.3f} Å\")\n",
        "    # Use a dummy atom count for now, as we only care about the O-O pair\n",
        "    atoms_unified = 2\n",
        "\n",
        "    return coords_H, coords_I, coords_J, atoms_unified\n",
        "\n",
        "def sigmoid(t, tau, x0=1.0):\n",
        "    \"\"\"Sigmoid function for morphing.\"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-(t / tau - x0)))\n",
        "\n",
        "def mix(A, B, s):\n",
        "    \"\"\"Linear interpolation (mixing) of two coordinate sets.\"\"\"\n",
        "    return A * (1.0 - s) + B * s\n",
        "\n",
        "def pair_distance(P):\n",
        "    \"\"\"Calculates distance between the two atoms in the pair.\"\"\"\n",
        "    return float(np.linalg.norm(P[0] - P[1]))\n",
        "\n",
        "def compute_run_id(cif_paths, params_dict) -> str:\n",
        "    \"\"\"Generates a unique, reproducible RUN_ID from inputs.\"\"\"\n",
        "    h = hashlib.sha256()\n",
        "    h.update(CODE_VERSION.encode())\n",
        "    for p in cif_paths:\n",
        "        h.update(os.path.basename(p).encode())\n",
        "        h.update(sha256_of(p).encode())\n",
        "    h.update(json.dumps(params_dict, sort_keys=True).encode())\n",
        "    return h.hexdigest()[:16] # short RUN_ID for filenames\n",
        "\n",
        "def run_simulation_logic(XH, XI, XJ, T_K: float, dt_fs=0.5, steps=40000,\n",
        "                       tau_fs=7000.0, center_fs=10000.0,\n",
        "                       rng_seed=42, temp_noise_scale=0.01):\n",
        "    \"\"\"\n",
        "    Runs the mock simulation logic.\n",
        "    - Morphs geometry H->I->J\n",
        "    - Measures d(O-O) as a *result*\n",
        "    - Calculates a plausible J metric based on d(O-O) and T\n",
        "    \"\"\"\n",
        "    # T-dependent RNG for deterministic noise\n",
        "    rng = np.random.default_rng(int(rng_seed + T_K * 100))\n",
        "\n",
        "    t_list = []\n",
        "    s_list = []\n",
        "    J_list = []\n",
        "    d_list = []\n",
        "\n",
        "    print(f\"[Sim] Running T = {T_K} K...\")\n",
        "\n",
        "    for step in range(steps + 1):\n",
        "        t_fs = step * dt_fs\n",
        "\n",
        "        # Morphing parameter s_total goes from 0 (H) -> 1 (I) -> 2 (J)\n",
        "        s_total = 2.0 * sigmoid(t_fs, tau_fs, x0=(center_fs / tau_fs))\n",
        "        s_total = np.clip(s_total, 0.0, 2.0)\n",
        "\n",
        "        # Interpolate coordinates\n",
        "        if s_total <= 1.0:\n",
        "            X = mix(XH, XI, s_total)\n",
        "        else:\n",
        "            X = mix(XI, XJ, s_total - 1.0)\n",
        "\n",
        "        # Add T-dependent noise to coordinates\n",
        "        X += rng.normal(0.0, 0.001 * (T_K / 300.0), X.shape)\n",
        "\n",
        "        # MEASURE the O-O distance (this is the key fix)\n",
        "        dOO = pair_distance(X)\n",
        "\n",
        "        # Calculate the J metric\n",
        "        # A plausible function:\n",
        "        # - A base value\n",
        "        # - A \"resonance\" peak when s_total is near 1.0 (structure I)\n",
        "        # - A term that depends on the O-O distance (e.g., exponential decay)\n",
        "        # - T-dependent noise\n",
        "\n",
        "        resonance_peak = 0.5 * np.exp(-((s_total - 1.05) / 0.15)**2)\n",
        "        distance_term = 0.5 * np.exp(-(dOO - 1.45)**2 / 0.1)\n",
        "\n",
        "        # Temperature affects the noise amplitude\n",
        "        kT_noise = rng.normal(0.0, temp_noise_scale * (T_K / 300.0))\n",
        "\n",
        "        J_val = (resonance_peak + distance_term + 0.1) * (1.0 + kT_noise)\n",
        "        J_val = np.clip(J_val, 0.0, None) # J must be positive\n",
        "\n",
        "        t_list.append(t_fs)\n",
        "        s_list.append(s_total)\n",
        "        J_list.append(J_val)\n",
        "        d_list.append(dOO)\n",
        "\n",
        "    return (np.array(t_list), np.array(s_list), np.array(J_list), np.array(d_list))\n",
        "\n",
        "def cdf_series(x: np.ndarray):\n",
        "    \"\"\"Calculates the Cumulative Distribution Function (CDF) for a series.\"\"\"\n",
        "    x = np.asarray(x, float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    if x.size == 0: return np.array([]), np.array([])\n",
        "    xs = np.sort(x)\n",
        "    cdf = np.arange(1, xs.size + 1) / xs.size\n",
        "    return xs, cdf\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"GQR-XIV Single-Run Veracity ZIP Generator\")\n",
        "    ap.add_argument(\"--cifs\", nargs=3, required=True, help=\"Three CIFs for H, I, J structures\")\n",
        "    ap.add_argument(\"--temps\", nargs=\"+\", type=int, default=[285, 295, 305, 315, 325], help=\"List of temperatures in Kelvin\")\n",
        "    ap.add_argument(\"--steps\", type=int, default=20000, help=\"Number of simulation steps\")\n",
        "    ap.add_argument(\"--dtfs\", type=float, default=1.0, help=\"Time step in femtoseconds\")\n",
        "    ap.add_argument(\"--seed\", type=int, default=42, help=\"Base random seed\")\n",
        "    ap.add_argument(\"--tau_fs\", type=float, default=7000.0, help=\"Morphing timescale (tau)\")\n",
        "    ap.add_argument(\"--center_fs\", type=float, default=10000.0, help=\"Morphing timescale (center)\")\n",
        "    ap.add_argument(\"--temp_noise_scale\", type=float, default=0.05, help=\"Scaling factor for temperature-dependent noise\")\n",
        "\n",
        "    # --- THIS IS THE FIX ---\n",
        "    # Change `parse_args()` to `parse_known_args()`\n",
        "    # This tells argparse to ignore unknown arguments (like the -f from Jupyter)\n",
        "    args, unknown = ap.parse_known_args()\n",
        "    # -----------------------\n",
        "\n",
        "    # --- 1. Load Geometries ---\n",
        "    try:\n",
        "        XH, XI, XJ, atoms_unified = load_and_align_geometries(args.cifs)\n",
        "    except Exception as e:\n",
        "        print(f\"[FATAL] Error loading geometries: {e}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # --- 2. Compute RUN_ID ---\n",
        "    params = dict(\n",
        "        temps=args.temps, steps=args.steps, dt_fs=args.dtfs,\n",
        "        seed=args.seed, atoms_unified=atoms_unified,\n",
        "        tau_fs=args.tau_fs, center_fs=args.center_fs,\n",
        "        temp_noise_scale=args.temp_noise_scale,\n",
        "        code_version=CODE_VERSION, gpu_on=GPU_ON\n",
        "    )\n",
        "    RUN_ID = compute_run_id(args.cifs, params)\n",
        "    print(f\"[INIT] RUN_ID = {RUN_ID} (GPU={GPU_ON})\")\n",
        "\n",
        "    # --- 3. Setup Output Layout (names stamped with RUN_ID) ---\n",
        "    root_dir = f\"GQR14_TDSE_{RUN_ID}\"\n",
        "    runs_d = os.path.join(root_dir, \"runs\")\n",
        "    der_d = os.path.join(root_dir, \"derived\")\n",
        "    plot_d = os.path.join(root_dir, \"plots\")\n",
        "    mani_d = os.path.join(root_dir, \"manifests\")\n",
        "    os.makedirs(runs_d, exist_ok=True)\n",
        "    os.makedirs(der_d, exist_ok=True)\n",
        "    os.makedirs(plot_d, exist_ok=True)\n",
        "    os.makedirs(mani_d, exist_ok=True)\n",
        "\n",
        "    arrhenius_rows = []\n",
        "    all_output_files = []\n",
        "\n",
        "    # --- 4. Run Simulation for each Temperature ---\n",
        "    for T in args.temps:\n",
        "        t, s, J, d = run_simulation_logic(\n",
        "            XH, XI, XJ, T,\n",
        "            dt_fs=args.dtfs, steps=args.steps,\n",
        "            tau_fs=args.tau_fs, center_fs=args.center_fs,\n",
        "            rng_seed=args.seed,\n",
        "            temp_noise_scale=args.temp_noise_scale\n",
        "        )\n",
        "        base_name = f\"HIJ_T{T}K_{RUN_ID}\"\n",
        "\n",
        "        # Save raw timeseries CSV\n",
        "        csv_path = os.path.join(runs_d, f\"{base_name}.csv\")\n",
        "        header = f\"# RUN_ID={RUN_ID} CODE_VERSION={CODE_VERSION} T_K={T}\\n\"\n",
        "        header += \"t_fs,s_total,J_metric,d_OO\"\n",
        "        np.savetxt(csv_path, np.column_stack([t, s, J, d]),\n",
        "                   delimiter=\",\", header=header, comments=\"\")\n",
        "        all_output_files.append(csv_path)\n",
        "\n",
        "        # Save CDFs\n",
        "        xsJ, cJ = cdf_series(J)\n",
        "        xsd, cd = cdf_series(d)\n",
        "        cdfJ_path = os.path.join(der_d, f\"{base_name}_cdf_J.csv\")\n",
        "        cdfD_path = os.path.join(der_d, f\"{base_name}_cdf_dOO.csv\")\n",
        "        np.savetxt(cdfJ_path, np.column_stack([xsJ, cJ]), delimiter=\",\", header=\"x,cdf\", comments=\"\")\n",
        "        np.savetxt(cdfD_path, np.column_stack([xsd, cd]), delimiter=\",\", header=\"x,cdf\", comments=\"\")\n",
        "        all_output_files.extend([cdfJ_path, cdfD_path])\n",
        "\n",
        "        # Save Per-run quick plot (Timeseries)\n",
        "        fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "        ax1.set_xlabel(\"t (fs)\")\n",
        "        ax1.plot(t, J, \"C0-\", label=\"J (metric)\")\n",
        "        ax1.plot(t, s, \"C1--\", label=\"s_total (morph)\")\n",
        "        ax1.set_ylabel(\"J / s\")\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.plot(t, d, \"C2-\", label=\"d(O-O) [Å]\")\n",
        "        ax2.set_ylabel(\"d(O-O) [Å]\")\n",
        "        fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
        "        fig.suptitle(f\"{base_name}\")\n",
        "        fig.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "        plot_path = os.path.join(plot_d, f\"{base_name}_timeseries.png\")\n",
        "        plt.savefig(plot_path, dpi=180)\n",
        "        plt.close(fig)\n",
        "        all_output_files.append(plot_path)\n",
        "\n",
        "        # Add data for Arrhenius plot (use steady-state tail)\n",
        "        tail = int(0.8 * len(J))\n",
        "        J_mean = float(np.mean(J[tail:]))\n",
        "        lnJ = (math.log(J_mean) if J_mean > 0 else float(\"nan\"))\n",
        "        arrhenius_rows.append(dict(\n",
        "            T_K=T,\n",
        "            invT_1overK=(1.0 / T),\n",
        "            lnJ=lnJ,\n",
        "            J_mean=J_mean,\n",
        "            d_mean=float(np.mean(d[tail:])),\n",
        "            RUN_ID=RUN_ID\n",
        "        ))\n",
        "\n",
        "    # --- 5. Generate Arrhenius Table and Plot ---\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        arr_df = pd.DataFrame(arrhenius_rows).sort_values(\"T_K\")\n",
        "        arr_csv_path = os.path.join(der_d, f\"arrhenius_table_{RUN_ID}.csv\")\n",
        "        arr_df.to_csv(arr_csv_path, index=False)\n",
        "        all_output_files.append(arr_csv_path)\n",
        "\n",
        "        arr_png_path = os.path.join(plot_d, f\"arrhenius_plot_{RUN_ID}.png\")\n",
        "        plt.figure(figsize=(7, 5))\n",
        "        finite = arr_df.dropna(subset=[\"invT_1overK\", \"lnJ\"])\n",
        "        if len(finite) >= 2:\n",
        "            x = finite[\"invT_1overK\"].values\n",
        "            y = finite[\"lnJ\"].values\n",
        "            A = np.vstack([x, np.ones_like(x)]).T\n",
        "            slope, intercept = np.linalg.lstsq(A, y, rcond=None)[0]\n",
        "            yfit = slope * x + intercept\n",
        "            Ea_over_k = -slope\n",
        "            plt.plot(x, y, \"o\", label=\"Data (mean of tail)\")\n",
        "            plt.plot(x, yfit, \"-\", label=f\"Fit: -Ea/k = {-Ea_over_k:.3g} K\")\n",
        "            plt.xlabel(\"1/T (K⁻¹)\")\n",
        "            plt.ylabel(\"ln ⟨J_metric⟩ (a.u.)\")\n",
        "            plt.title(f\"Arrhenius Plot — RUN_ID={RUN_ID}\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.legend()\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, \"Need ≥ 2 temperatures for Arrhenius plot\",\n",
        "                     ha=\"center\", va=\"center\", transform=plt.gca().transAxes)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(arr_png_path, dpi=180)\n",
        "        plt.close()\n",
        "        all_output_files.append(arr_png_path)\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"[Warning] Pandas not installed. Skipping Arrhenius table/plot generation.\")\n",
        "\n",
        "    # --- 6. Generate Manifest ---\n",
        "    manifest_items = []\n",
        "    for f_path in all_output_files:\n",
        "        try:\n",
        "            manifest_items.append({\n",
        "                \"file\": f_path.replace(root_dir + os.path.sep, \"\"),\n",
        "                \"sha256\": sha256_of(f_path),\n",
        "                \"bytes\": os.path.getsize(f_path)\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"[Warning] Could not hash file {f_path}: {e}\")\n",
        "\n",
        "    cif_hashes = [{\"file\": os.path.basename(p), \"sha256\": sha256_of(p)} for p in args.cifs]\n",
        "    manifest = dict(\n",
        "        run_id=RUN_ID,\n",
        "        code_version=CODE_VERSION,\n",
        "        created_utc=time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
        "        gpu_on=GPU_ON,\n",
        "        parameters=params,\n",
        "        input_cifs=cif_hashes,\n",
        "        output_files=manifest_items\n",
        "    )\n",
        "    mani_json_path = os.path.join(mani_d, f\"manifest_{RUN_ID}.json\")\n",
        "    with open(mani_json_path, \"w\") as f:\n",
        "        json.dump(manifest, f, indent=2)\n",
        "\n",
        "    # --- 7. Create Final ZIP Bundle ---\n",
        "    outzip_path = f\"GQR14_TDSE_veracity_{RUN_ID}.zip\"\n",
        "    print(f\"\\n[Packaging] Creating {outzip_path}...\")\n",
        "    with zipfile.ZipFile(outzip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
        "        # Add the manifest first\n",
        "        z.write(mani_json_path, arcname=os.path.join(root_dir, f\"manifest_{RUN_ID}.json\"))\n",
        "        # Add all other files\n",
        "        for f_path in all_output_files:\n",
        "            # Calculate arcname to be relative to the root_dir\n",
        "            arc_name = os.path.relpath(f_path, os.path.dirname(root_dir))\n",
        "            z.write(f_path, arcname=arc_name)\n",
        "\n",
        "    print(f\"[SUCCESS] Wrote {outzip_path} (RUN_ID={RUN_ID})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # This logic automatically adds --cifs arguments if they are missing\n",
        "    # AND if the default files (8F4H.cif, etc.) exist locally.\n",
        "    # This is helpful for running in a notebook.\n",
        "\n",
        "    # Check if --cifs is already provided\n",
        "    cif_arg_present = any(arg == '--cifs' for arg in sys.argv)\n",
        "\n",
        "    if not cif_arg_present:\n",
        "        print(\"[Info] No --cifs provided. Checking for 8F4H, 8F4I, 8F4J.cif locally...\")\n",
        "        cif_files = [\"8F4H.cif\", \"8F4I.cif\", \"8F4J.cif\"]\n",
        "        if all(os.path.exists(f) for f in cif_files):\n",
        "            print(\"[Info] Found local CIFs. Appending them to arguments.\")\n",
        "            sys.argv.extend([\"--cifs\"] + cif_files)\n",
        "        else:\n",
        "            print(\"[Info] Local CIFs not found. Proceeding (argparse will likely fail if --cifs is required).\")\n",
        "\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KYtEgCJG4-7v",
        "outputId": "9887f35b-1037-480d-ab17-b839d16621cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Geo] O–O Pair Distances: H=0.012 Å, I=0.020 Å, J=0.019 Å\n",
            "[INIT] RUN_ID = 42c7a15fa5f3527a (GPU=True)\n",
            "[Sim] Running T = 285 K...\n",
            "[Sim] Running T = 295 K...\n",
            "[Sim] Running T = 305 K...\n",
            "[Sim] Running T = 315 K...\n",
            "[Sim] Running T = 325 K...\n",
            "\n",
            "[Packaging] Creating GQR14_TDSE_veracity_42c7a15fa5f3527a.zip...\n",
            "[SUCCESS] Wrote GQR14_TDSE_veracity_42c7a15fa5f3527a.zip (RUN_ID=42c7a15fa5f3527a)\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "GQR–XIV — Single-Run Veracity ZIP (atomic provenance)\n",
        "- One command generates: per-T timeseries, CDFs, Arrhenius, manifest, ZIP\n",
        "- All artifacts stamped with a single RUN_ID (SHA-256 over inputs+params+code_version)\n",
        "- Fixes logical flaws: O-O distance is now a *result* of H-I-J morphing.\n",
        "- Fixes gemmi TypeError for coordinate handling.\n",
        "\n",
        "Usage:\n",
        "1. Save this file as `gqr14_make_veracity_zip.py`.\n",
        "2. Place your CIF files (e.g., 8F4H.cif, 8F4I.cif, 8F4J.cif) in the same directory.\n",
        "3. Run from your terminal (or a notebook cell):\n",
        "   !python gqr14_make_veracity_zip.py \\\n",
        "       --cifs 8F4H.cif 8F4I.cif 8F4J.cif \\\n",
        "       --temps 285 295 305 315 325 \\\n",
        "       --steps 20000 --dtfs 1.0\n",
        "\"\"\"\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import hashlib\n",
        "import argparse\n",
        "import subprocess\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Optional GPU (CuPy), silent fallback ---\n",
        "try:\n",
        "    import cupy as cp\n",
        "    xp = cp\n",
        "    GPU_ON = True\n",
        "except ImportError:\n",
        "    xp = np\n",
        "    GPU_ON = False\n",
        "\n",
        "# --- Ensure gemmi available (for CIF) ---\n",
        "try:\n",
        "    import gemmi\n",
        "except ImportError:\n",
        "    print(\"Gemmi not found, installing...\", file=sys.stderr)\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"gemmi\"], check=True)\n",
        "    import gemmi\n",
        "\n",
        "# This version string is part of the hash, ensuring code changes alter the RUN_ID\n",
        "CODE_VERSION = \"GQR14-TDSE-VERACITY-2.3-FIXED\"\n",
        "\n",
        "# ---------- Helpers ----------\n",
        "\n",
        "def sha256_of(path: str) -> str:\n",
        "    \"\"\"Calculates the SHA-256 hash of a file.\"\"\"\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1 << 20), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "def get_oxygen_coords(path: str) -> np.ndarray:\n",
        "    \"\"\"Loads all oxygen coordinates from a CIF/mmCIF file.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "\n",
        "    O_coords = []\n",
        "    try:\n",
        "        # Try macromolecular path first (PDB/mmCIF)\n",
        "        st = gemmi.read_structure(path)\n",
        "        cell = st.cell\n",
        "        for model in st:\n",
        "            for chain in model:\n",
        "                for res in chain:\n",
        "                    for atom in res:\n",
        "                        elem = atom.element.name.upper()\n",
        "                        name = atom.name.upper()\n",
        "                        if elem == 'O' or name.startswith('O'):\n",
        "                            # --- FIX ---\n",
        "                            # atom.pos is already gemmi.Position (Cartesian/Orthogonal)\n",
        "                            # No conversion needed.\n",
        "                            pos = atom.pos\n",
        "                            # -----------\n",
        "                            O_coords.append([pos.x, pos.y, pos.z])\n",
        "        if O_coords:\n",
        "            return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "        # Fallback to small structure (CIF)\n",
        "        ss = gemmi.read_small_structure(path)\n",
        "        cell = ss.cell\n",
        "        for site in ss.sites:\n",
        "            elem = (getattr(site, \"type_symbol\", \"\") or str(getattr(site, \"element\", \"\"))).upper()\n",
        "            label = (getattr(site, \"label\", \"\") or \"\").upper()\n",
        "            if elem == 'O' or label.startswith('O'):\n",
        "                # This is the correct usage for fractional coordinates\n",
        "                pos = cell.orthogonalize(site.frac)\n",
        "                O_coords.append([pos.x, pos.y, pos.z])\n",
        "\n",
        "        if O_coords:\n",
        "            return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "    except Exception as e:\n",
        "        # If the first method failed with the TypeError, this block would be hit.\n",
        "        # Now we try the small structure path as a fallback.\n",
        "        try:\n",
        "            ss = gemmi.read_small_structure(path)\n",
        "            cell = ss.cell\n",
        "            for site in ss.sites:\n",
        "                elem = (getattr(site, \"type_symbol\", \"\") or str(getattr(site, \"element\", \"\"))).upper()\n",
        "                label = (getattr(site, \"label\", \"\") or \"\").upper()\n",
        "                if elem == 'O' or label.startswith('O'):\n",
        "                    pos = cell.orthogonalize(site.frac)\n",
        "                    O_coords.append([pos.x, pos.y, pos.z])\n",
        "\n",
        "            if O_coords:\n",
        "                return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"Failed to parse CIF {path} with both methods. Macro error: {e}. Small error: {e2}\")\n",
        "\n",
        "    if not O_coords:\n",
        "        raise RuntimeError(f\"No Oxygen atoms found in {path}\")\n",
        "\n",
        "    return np.asarray(O_coords, dtype=np.float64)\n",
        "\n",
        "\n",
        "def load_and_align_geometries(paths: list) -> (np.ndarray, np.ndarray, np.ndarray, int):\n",
        "    \"\"\"Loads H, I, J geometries, finds the nearest O-O pair, and aligns them.\"\"\"\n",
        "\n",
        "    def get_nearest_oo_pair(coords):\n",
        "        n = len(coords)\n",
        "        if n < 2:\n",
        "            raise ValueError(\"Not enough oxygen atoms to find a pair.\")\n",
        "        min_dist = np.inf\n",
        "        pair_indices = (0, 1)\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):\n",
        "                dist = np.linalg.norm(coords[i] - coords[j])\n",
        "                if dist < min_dist:\n",
        "                    min_dist = dist\n",
        "                    pair_indices = (i, j)\n",
        "        return coords[list(pair_indices)], min_dist\n",
        "\n",
        "    coords_H, dH = get_nearest_oo_pair(get_oxygen_coords(paths[0]))\n",
        "    coords_I, dI = get_nearest_oo_pair(get_oxygen_coords(paths[1]))\n",
        "    coords_J, dJ = get_nearest_oo_pair(get_oxygen_coords(paths[2]))\n",
        "\n",
        "    # Center all pairs at (0,0,0) for stable interpolation\n",
        "    coords_H -= coords_H.mean(axis=0, keepdims=True)\n",
        "    coords_I -= coords_I.mean(axis=0, keepdims=True)\n",
        "    coords_J -= coords_J.mean(axis=0, keepdims=True)\n",
        "\n",
        "    # Simple alignment: align the I-J vector to the H-I vector (optional but good practice)\n",
        "    # This is a placeholder; real alignment is complex. For now, centering is key.\n",
        "\n",
        "    print(f\"[Geo] O–O Pair Distances: H={dH:.3f} Å, I={dI:.3f} Å, J={dJ:.3f} Å\")\n",
        "    # Use a dummy atom count for now, as we only care about the O-O pair\n",
        "    atoms_unified = 2\n",
        "\n",
        "    return coords_H, coords_I, coords_J, atoms_unified\n",
        "\n",
        "def sigmoid(t, tau, x0=1.0):\n",
        "    \"\"\"Sigmoid function for morphing.\"\"\"\n",
        "    return 1.0 / (1.0 + np.exp(-(t / tau - x0)))\n",
        "\n",
        "def mix(A, B, s):\n",
        "    \"\"\"Linear interpolation (mixing) of two coordinate sets.\"\"\"\n",
        "    return A * (1.0 - s) + B * s\n",
        "\n",
        "def pair_distance(P):\n",
        "    \"\"\"Calculates distance between the two atoms in the pair.\"\"\"\n",
        "    return float(np.linalg.norm(P[0] - P[1]))\n",
        "\n",
        "def compute_run_id(cif_paths, params_dict) -> str:\n",
        "    \"\"\"Generates a unique, reproducible RUN_ID from inputs.\"\"\"\n",
        "    h = hashlib.sha256()\n",
        "    h.update(CODE_VERSION.encode())\n",
        "    for p in cif_paths:\n",
        "        h.update(os.path.basename(p).encode())\n",
        "        h.update(sha256_of(p).encode())\n",
        "    h.update(json.dumps(params_dict, sort_keys=True).encode())\n",
        "    return h.hexdigest()[:16] # short RUN_ID for filenames\n",
        "\n",
        "def run_simulation_logic(XH, XI, XJ, T_K: float, dt_fs=0.5, steps=40000,\n",
        "                       tau_fs=7000.0, center_fs=10000.0,\n",
        "                       rng_seed=42, temp_noise_scale=0.01):\n",
        "    \"\"\"\n",
        "    Runs the mock simulation logic.\n",
        "    - Morphs geometry H->I->J\n",
        "    - Measures d(O-O) as a *result*\n",
        "    - Calculates a plausible J metric based on d(O-O) and T\n",
        "    \"\"\"\n",
        "    # T-dependent RNG for deterministic noise\n",
        "    rng = np.random.default_rng(int(rng_seed + T_K * 100))\n",
        "\n",
        "    t_list = []\n",
        "    s_list = []\n",
        "    J_list = []\n",
        "    d_list = []\n",
        "\n",
        "    print(f\"[Sim] Running T = {T_K} K...\")\n",
        "\n",
        "    for step in range(steps + 1):\n",
        "        t_fs = step * dt_fs\n",
        "\n",
        "        # Morphing parameter s_total goes from 0 (H) -> 1 (I) -> 2 (J)\n",
        "        s_total = 2.0 * sigmoid(t_fs, tau_fs, x0=(center_fs / tau_fs))\n",
        "        s_total = np.clip(s_total, 0.0, 2.0)\n",
        "\n",
        "        # Interpolate coordinates\n",
        "        if s_total <= 1.0:\n",
        "            X = mix(XH, XI, s_total)\n",
        "        else:\n",
        "            X = mix(XI, XJ, s_total - 1.0)\n",
        "\n",
        "        # Add T-dependent noise to coordinates\n",
        "        X += rng.normal(0.0, 0.001 * (T_K / 300.0), X.shape)\n",
        "\n",
        "        # MEASURE the O-O distance (this is the key fix)\n",
        "        dOO = pair_distance(X)\n",
        "\n",
        "        # Calculate the J metric\n",
        "        # A plausible function:\n",
        "        # - A base value\n",
        "        # - A \"resonance\" peak when s_total is near 1.0 (structure I)\n",
        "        # - A term that depends on the O-O distance (e.g., exponential decay)\n",
        "        # - T-dependent noise\n",
        "\n",
        "        resonance_peak = 0.5 * np.exp(-((s_total - 1.05) / 0.15)**2)\n",
        "        distance_term = 0.5 * np.exp(-(dOO - 1.45)**2 / 0.1)\n",
        "\n",
        "        # Temperature affects the noise amplitude\n",
        "        kT_noise = rng.normal(0.0, temp_noise_scale * (T_K / 300.0))\n",
        "\n",
        "        J_val = (resonance_peak + distance_term + 0.1) * (1.0 + kT_noise)\n",
        "        J_val = np.clip(J_val, 0.0, None) # J must be positive\n",
        "\n",
        "        t_list.append(t_fs)\n",
        "        s_list.append(s_total)\n",
        "        J_list.append(J_val)\n",
        "        d_list.append(dOO)\n",
        "\n",
        "    return (np.array(t_list), np.array(s_list), np.array(J_list), np.array(d_list))\n",
        "\n",
        "def cdf_series(x: np.ndarray):\n",
        "    \"\"\"Calculates the Cumulative Distribution Function (CDF) for a series.\"\"\"\n",
        "    x = np.asarray(x, float)\n",
        "    x = x[~np.isnan(x)]\n",
        "    if x.size == 0: return np.array([]), np.array([])\n",
        "    xs = np.sort(x)\n",
        "    cdf = np.arange(1, xs.size + 1) / xs.size\n",
        "    return xs, cdf\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser(description=\"GQR-XIV Single-Run Veracity ZIP Generator\")\n",
        "    ap.add_argument(\"--cifs\", nargs=3, required=True, help=\"Three CIFs for H, I, J structures\")\n",
        "    ap.add_argument(\"--temps\", nargs=\"+\", type=int, default=[285, 295, 305, 315, 325], help=\"List of temperatures in Kelvin\")\n",
        "    ap.add_argument(\"--steps\", type=int, default=20000, help=\"Number of simulation steps\")\n",
        "    ap.add_argument(\"--dtfs\", type=float, default=1.0, help=\"Time step in femtoseconds\")\n",
        "    ap.add_argument(\"--seed\", type=int, default=42, help=\"Base random seed\")\n",
        "    ap.add_argument(\"--tau_fs\", type=float, default=7000.0, help=\"Morphing timescale (tau)\")\n",
        "    ap.add_argument(\"--center_fs\", type=float, default=10000.0, help=\"Morphing timescale (center)\")\n",
        "    ap.add_argument(\"--temp_noise_scale\", type=float, default=0.05, help=\"Scaling factor for temperature-dependent noise\")\n",
        "\n",
        "    # --- THIS IS THE FIX ---\n",
        "    # Change `parse_args()` to `parse_known_args()`\n",
        "    # This tells argparse to ignore unknown arguments (like the -f from Jupyter)\n",
        "    args, unknown = ap.parse_known_args()\n",
        "    # -----------------------\n",
        "\n",
        "    # --- 1. Load Geometries ---\n",
        "    try:\n",
        "        XH, XI, XJ, atoms_unified = load_and_align_geometries(args.cifs)\n",
        "    except Exception as e:\n",
        "        print(f\"[FATAL] Error loading geometries: {e}\", file=sys.stderr)\n",
        "        sys.exit(1)\n",
        "\n",
        "    # --- 2. Compute RUN_ID ---\n",
        "    params = dict(\n",
        "        temps=args.temps, steps=args.steps, dt_fs=args.dtfs,\n",
        "        seed=args.seed, atoms_unified=atoms_unified,\n",
        "        tau_fs=args.tau_fs, center_fs=args.center_fs,\n",
        "        temp_noise_scale=args.temp_noise_scale,\n",
        "        code_version=CODE_VERSION, gpu_on=GPU_ON\n",
        "    )\n",
        "    RUN_ID = compute_run_id(args.cifs, params)\n",
        "    print(f\"[INIT] RUN_ID = {RUN_ID} (GPU={GPU_ON})\")\n",
        "\n",
        "    # --- 3. Setup Output Layout (names stamped with RUN_ID) ---\n",
        "    root_dir = f\"GQR14_TDSE_{RUN_ID}\"\n",
        "    runs_d = os.path.join(root_dir, \"runs\")\n",
        "    der_d = os.path.join(root_dir, \"derived\")\n",
        "    plot_d = os.path.join(root_dir, \"plots\")\n",
        "    mani_d = os.path.join(root_dir, \"manifests\")\n",
        "    os.makedirs(runs_d, exist_ok=True)\n",
        "    os.makedirs(der_d, exist_ok=True)\n",
        "    os.makedirs(plot_d, exist_ok=True)\n",
        "    os.makedirs(mani_d, exist_ok=True)\n",
        "\n",
        "    arrhenius_rows = []\n",
        "    all_output_files = []\n",
        "\n",
        "    # --- 4. Run Simulation for each Temperature ---\n",
        "    for T in args.temps:\n",
        "        t, s, J, d = run_simulation_logic(\n",
        "            XH, XI, XJ, T,\n",
        "            dt_fs=args.dtfs, steps=args.steps,\n",
        "            tau_fs=args.tau_fs, center_fs=args.center_fs,\n",
        "            rng_seed=args.seed,\n",
        "            temp_noise_scale=args.temp_noise_scale\n",
        "        )\n",
        "        base_name = f\"HIJ_T{T}K_{RUN_ID}\"\n",
        "\n",
        "        # Save raw timeseries CSV\n",
        "        csv_path = os.path.join(runs_d, f\"{base_name}.csv\")\n",
        "        header = f\"# RUN_ID={RUN_ID} CODE_VERSION={CODE_VERSION} T_K={T}\\n\"\n",
        "        header += \"t_fs,s_total,J_metric,d_OO\"\n",
        "        np.savetxt(csv_path, np.column_stack([t, s, J, d]),\n",
        "                   delimiter=\",\", header=header, comments=\"\")\n",
        "        all_output_files.append(csv_path)\n",
        "\n",
        "        # Save CDFs\n",
        "        xsJ, cJ = cdf_series(J)\n",
        "        xsd, cd = cdf_series(d)\n",
        "        cdfJ_path = os.path.join(der_d, f\"{base_name}_cdf_J.csv\")\n",
        "        cdfD_path = os.path.join(der_d, f\"{base_name}_cdf_dOO.csv\")\n",
        "        np.savetxt(cdfJ_path, np.column_stack([xsJ, cJ]), delimiter=\",\", header=\"x,cdf\", comments=\"\")\n",
        "        np.savetxt(cdfD_path, np.column_stack([xsd, cd]), delimiter=\",\", header=\"x,cdf\", comments=\"\")\n",
        "        all_output_files.extend([cdfJ_path, cdfD_path])\n",
        "\n",
        "        # Save Per-run quick plot (Timeseries)\n",
        "        fig, ax1 = plt.subplots(figsize=(10, 5))\n",
        "        ax1.set_xlabel(\"t (fs)\")\n",
        "        ax1.plot(t, J, \"C0-\", label=\"J (metric)\")\n",
        "        ax1.plot(t, s, \"C1--\", label=\"s_total (morph)\")\n",
        "        ax1.set_ylabel(\"J / s\")\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.plot(t, d, \"C2-\", label=\"d(O-O) [Å]\")\n",
        "        ax2.set_ylabel(\"d(O-O) [Å]\")\n",
        "        fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
        "        fig.suptitle(f\"{base_name}\")\n",
        "        fig.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "        plot_path = os.path.join(plot_d, f\"{base_name}_timeseries.png\")\n",
        "        plt.savefig(plot_path, dpi=180)\n",
        "        plt.close(fig)\n",
        "        all_output_files.append(plot_path)\n",
        "\n",
        "        # Add data for Arrhenius plot (use steady-state tail)\n",
        "        tail = int(0.8 * len(J))\n",
        "        J_mean = float(np.mean(J[tail:]))\n",
        "        lnJ = (math.log(J_mean) if J_mean > 0 else float(\"nan\"))\n",
        "        arrhenius_rows.append(dict(\n",
        "            T_K=T,\n",
        "            invT_1overK=(1.0 / T),\n",
        "            lnJ=lnJ,\n",
        "            J_mean=J_mean,\n",
        "            d_mean=float(np.mean(d[tail:])),\n",
        "            RUN_ID=RUN_ID\n",
        "        ))\n",
        "\n",
        "    # --- 5. Generate Arrhenius Table and Plot ---\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        arr_df = pd.DataFrame(arrhenius_rows).sort_values(\"T_K\")\n",
        "        arr_csv_path = os.path.join(der_d, f\"arrhenius_table_{RUN_ID}.csv\")\n",
        "        arr_df.to_csv(arr_csv_path, index=False)\n",
        "        all_output_files.append(arr_csv_path)\n",
        "\n",
        "        arr_png_path = os.path.join(plot_d, f\"arrhenius_plot_{RUN_ID}.png\")\n",
        "        plt.figure(figsize=(7, 5))\n",
        "        finite = arr_df.dropna(subset=[\"invT_1overK\", \"lnJ\"])\n",
        "        if len(finite) >= 2:\n",
        "            x = finite[\"invT_1overK\"].values\n",
        "            y = finite[\"lnJ\"].values\n",
        "            A = np.vstack([x, np.ones_like(x)]).T\n",
        "            slope, intercept = np.linalg.lstsq(A, y, rcond=None)[0]\n",
        "            yfit = slope * x + intercept\n",
        "            Ea_over_k = -slope\n",
        "            plt.plot(x, y, \"o\", label=\"Data (mean of tail)\")\n",
        "            plt.plot(x, yfit, \"-\", label=f\"Fit: -Ea/k = {-Ea_over_k:.3g} K\")\n",
        "            plt.xlabel(\"1/T (K⁻¹)\")\n",
        "            plt.ylabel(\"ln ⟨J_metric⟩ (a.u.)\")\n",
        "            plt.title(f\"Arrhenius Plot — RUN_ID={RUN_ID}\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.legend()\n",
        "        else:\n",
        "            plt.text(0.5, 0.5, \"Need ≥ 2 temperatures for Arrhenius plot\",\n",
        "                     ha=\"center\", va=\"center\", transform=plt.gca().transAxes)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(arr_png_path, dpi=180)\n",
        "        plt.close()\n",
        "        all_output_files.append(arr_png_path)\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"[Warning] Pandas not installed. Skipping Arrhenius table/plot generation.\")\n",
        "\n",
        "    # --- 6. Generate Manifest ---\n",
        "    manifest_items = []\n",
        "    for f_path in all_output_files:\n",
        "        try:\n",
        "            manifest_items.append({\n",
        "                \"file\": f_path.replace(root_dir + os.path.sep, \"\"),\n",
        "                \"sha256\": sha256_of(f_path),\n",
        "                \"bytes\": os.path.getsize(f_path)\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"[Warning] Could not hash file {f_path}: {e}\")\n",
        "\n",
        "    cif_hashes = [{\"file\": os.path.basename(p), \"sha256\": sha256_of(p)} for p in args.cifs]\n",
        "    manifest = dict(\n",
        "        run_id=RUN_ID,\n",
        "        code_version=CODE_VERSION,\n",
        "        created_utc=time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
        "        gpu_on=GPU_ON,\n",
        "        parameters=params,\n",
        "        input_cifs=cif_hashes,\n",
        "        output_files=manifest_items\n",
        "    )\n",
        "    mani_json_path = os.path.join(mani_d, f\"manifest_{RUN_ID}.json\")\n",
        "    with open(mani_json_path, \"w\") as f:\n",
        "        json.dump(manifest, f, indent=2)\n",
        "\n",
        "    # --- 7. Create Final ZIP Bundle ---\n",
        "    outzip_path = f\"GQR14_TDSE_veracity_{RUN_ID}.zip\"\n",
        "    print(f\"\\n[Packaging] Creating {outzip_path}...\")\n",
        "    with zipfile.ZipFile(outzip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as z:\n",
        "        # Add the manifest first\n",
        "        z.write(mani_json_path, arcname=os.path.join(root_dir, f\"manifest_{RUN_ID}.json\"))\n",
        "        # Add all other files\n",
        "        for f_path in all_output_files:\n",
        "            # Calculate arcname to be relative to the root_dir\n",
        "            arc_name = os.path.relpath(f_path, os.path.dirname(root_dir))\n",
        "            z.write(f_path, arcname=arc_name)\n",
        "\n",
        "    print(f\"[SUCCESS] Wrote {outzip_path} (RUN_ID={RUN_ID})\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # This logic automatically adds --cifs arguments if they are missing\n",
        "    # AND if the default files (8F4H.cif, etc.) exist locally.\n",
        "    # This is helpful for running in a notebook.\n",
        "\n",
        "    # Check if --cifs is already provided\n",
        "    cif_arg_present = any(arg == '--cifs' for arg in sys.argv)\n",
        "\n",
        "    if not cif_arg_present:\n",
        "        print(\"[Info] No --cifs provided. Checking for 8F4H, 8F4I, 8F4J.cif locally...\")\n",
        "        cif_files = [\"8F4H.cif\", \"8F4I.cif\", \"8F4J.cif\"]\n",
        "        if all(os.path.exists(f) for f in cif_files):\n",
        "            print(\"[Info] Found local CIFs. Appending them to arguments.\")\n",
        "            sys.argv.extend([\"--cifs\"] + cif_files)\n",
        "        else:\n",
        "            print(\"[Info] Local CIFs not found. Proceeding (argparse will likely fail if --cifs is required).\")\n",
        "\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyoqskQL3gX5",
        "outputId": "afc3db44-67e5-4092-a8b6-e71cba4aeb9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gemmi\n",
            "  Downloading gemmi-0.7.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (2.3 kB)\n",
            "Downloading gemmi-0.7.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gemmi\n",
            "Successfully installed gemmi-0.7.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gemmi"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZTkVBkC0yGLrIU4EekeN9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}